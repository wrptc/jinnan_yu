{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('jinnan_round1_train_20181227.csv', encoding = 'gb18030')\n",
    "test  = pd.read_csv('jinnan_round1_testA_20181227.csv', encoding = 'gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 0.9863896848137536\n",
      "A2 0.9699140401146131\n",
      "A3 0.9570200573065902\n",
      "A4 0.9570200573065902\n",
      "B2 0.9842406876790831\n"
     ]
    }
   ],
   "source": [
    "good_cols = list(train.columns)\n",
    "for col in train.columns:\n",
    "    rate = train[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "    if rate > 0.9:\n",
    "        good_cols.remove(col)\n",
    "        print(col,rate)\n",
    "\n",
    "train = train[train['收率']>0.87]\n",
    "        \n",
    "train = train[good_cols]\n",
    "good_cols.remove('收率')\n",
    "test  = test[good_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['收率']\n",
    "del train['收率']\n",
    "data = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "data = data.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeTranSecond(t):\n",
    "    try:\n",
    "        t,m,s=t.split(\":\")\n",
    "    except:\n",
    "        if t=='1900/1/9 7:00':\n",
    "            return 7*3600/3600\n",
    "        elif t=='1900/1/1 2:30':\n",
    "            return (2*3600+30*60)/3600\n",
    "        elif t==-1:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    try:\n",
    "        tm = (int(t)*3600+int(m)*60+int(s))/3600\n",
    "    except:\n",
    "        return (30*60)/3600\n",
    "    \n",
    "    return tm\n",
    "for f in ['A5','A7','A9','A11','A14','A16','A24','A26','B5','B7']:\n",
    "    data[f] = data[f].apply(timeTranSecond)\n",
    "\n",
    "def getDuration(se):\n",
    "    try:\n",
    "        sh,sm,eh,em=re.findall(r\"\\d+\\.?\\d*\",se)\n",
    "    except:\n",
    "        if se == -1:\n",
    "            return -1 \n",
    "        \n",
    "    try:\n",
    "        if int(sh)>int(eh):\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600 + 24\n",
    "        else:\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600\n",
    "    except:\n",
    "        if se=='19:-20:05':\n",
    "            return 1\n",
    "        elif se=='15:00-1600':\n",
    "            return 1\n",
    "    \n",
    "    return tm\n",
    "\n",
    "def get_start(se):\n",
    "    try:\n",
    "        sh, sm, eh, em = re.findall(r'\\d+\\.?d*', se)\n",
    "    except:\n",
    "        if se == -1:\n",
    "            return -1\n",
    "    try:\n",
    "        tm = (int(eh) * 3600 + int(em) * 60)/3600\n",
    "    except:\n",
    "        if se == '19:-20:05':\n",
    "            return 19\n",
    "        elif se == '15:00-1600':\n",
    "            return 15\n",
    "    return tm\n",
    "for f in ['A20','A28','B4','B9','B10','B11']:\n",
    "    data[f+'_diff'] = data.apply(lambda df: getDuration(df[f]), axis=1)\n",
    "for f in ['A20','A28','B4','B9','B10','B11']:\n",
    "    data[f] = data.apply(lambda df: get_start(df[f]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['样本id'] = data['样本id'].apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "categorical_columns = [f for f in data.columns if f not in ['样本id']]\n",
    "numerical_columns = [f for f in data.columns if f not in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1381, 39)\n",
      "(150, 39)\n"
     ]
    }
   ],
   "source": [
    "for f in categorical_columns:\n",
    "    data[f] = data[f].map(dict(zip(data[f].unique(), range(0, data[f].nunique()))))\n",
    "train = data[:train.shape[0]]\n",
    "test  = data[train.shape[0]:]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1381, 335)\n",
      "(150, 334)\n"
     ]
    }
   ],
   "source": [
    "train['target'] = target\n",
    "train['intTarget'] = pd.cut(train['target'], 5, labels=False)\n",
    "train = pd.get_dummies(train, columns=['intTarget'])\n",
    "li = ['intTarget_0.0','intTarget_1.0','intTarget_2.0','intTarget_3.0','intTarget_4.0']\n",
    "mean_columns = []\n",
    "for f1 in categorical_columns:\n",
    "    cate_rate = train[f1].value_counts(normalize=True, dropna=False).values[0]\n",
    "    if cate_rate < 0.90:\n",
    "        for f2 in li:\n",
    "            col_mean = f1 + f2 + '_mean'\n",
    "            col_name = 'B14_to_'+f1+\"_\"+f2+'_mean'\n",
    "            mean_columns.append(col_name)\n",
    "            #mean_columns.append(col_mean)\n",
    "            order_label = train.groupby([f1])[f2].mean()\n",
    "            train[col_name] = train['B14'].map(order_label)\n",
    "            train[col_mean] = train[f1].map(order_label)\n",
    "            miss_rate = train[col_name].isnull().sum() * 100 / train[col_name].shape[0]\n",
    "            if miss_rate > 0:\n",
    "                train = train.drop([col_name], axis=1)\n",
    "                mean_columns.remove(col_name)\n",
    "            else:\n",
    "                test[col_name] = test['B14'].map(order_label)\n",
    "            miss_rate = train[col_mean].isnull().sum() * 100 / train[col_mean].shape[0]\n",
    "            if miss_rate > 0:\n",
    "                train = train.drop([col_mean], axis=1)\n",
    "                mean_columns.remove(col_mean)\n",
    "            else:\n",
    "                test[col_mean] = test[f1].map(order_label)\n",
    "            \n",
    "                \n",
    "train.drop(li, axis=1, inplace=True)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_col = mean_columns + ['target']\n",
    "corr_spy = train\n",
    "corr_spy = pd.DataFrame(corr_spy, columns=corr_col)\n",
    "good_mean = list(corr_spy.corr()['target'].abs().sort_values()[int(len(mean_columns)*0.50):-1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f1 in good_mean:\n",
    "#     for f2 in good_mean:\n",
    "#         col_name = f1 + 'X' + f2\n",
    "#         if f1 == f2:\n",
    "#             pass\n",
    "#         else:\n",
    "#             good_mean.append(col_name)\n",
    "#             train[col_name] = train[f1] * train[f2]\n",
    "#             test[col_name] = test[f1] * test[f2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1381, 1686)\n",
      "(150, 1686)\n"
     ]
    }
   ],
   "source": [
    "X_train = train[mean_columns+numerical_columns].values\n",
    "X_test = test[mean_columns+numerical_columns].values\n",
    "# one hot\n",
    "enc = OneHotEncoder()\n",
    "for f in categorical_columns:\n",
    "    enc.fit(data[f].values.reshape(-1, 1))\n",
    "    X_train = sparse.hstack((X_train, enc.transform(train[f].values.reshape(-1, 1))), 'csr')\n",
    "    X_test = sparse.hstack((X_test, enc.transform(test[f].values.reshape(-1, 1))), 'csr')\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000172086\tvalid_1's l2: 0.000217744\n",
      "[400]\ttraining's l2: 0.000115985\tvalid_1's l2: 0.000158768\n",
      "[600]\ttraining's l2: 9.88312e-05\tvalid_1's l2: 0.000143687\n",
      "[800]\ttraining's l2: 9.14779e-05\tvalid_1's l2: 0.000138355\n",
      "[1000]\ttraining's l2: 8.70531e-05\tvalid_1's l2: 0.000135142\n",
      "[1200]\ttraining's l2: 8.37233e-05\tvalid_1's l2: 0.000133138\n",
      "[1400]\ttraining's l2: 8.11962e-05\tvalid_1's l2: 0.000131632\n",
      "[1600]\ttraining's l2: 7.90949e-05\tvalid_1's l2: 0.000130356\n",
      "[1800]\ttraining's l2: 7.74613e-05\tvalid_1's l2: 0.000129425\n",
      "[2000]\ttraining's l2: 7.59843e-05\tvalid_1's l2: 0.000128693\n",
      "[2200]\ttraining's l2: 7.46075e-05\tvalid_1's l2: 0.000128212\n",
      "Early stopping, best iteration is:\n",
      "[2209]\ttraining's l2: 7.45401e-05\tvalid_1's l2: 0.000128198\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000176084\tvalid_1's l2: 0.000190293\n",
      "[400]\ttraining's l2: 0.000121218\tvalid_1's l2: 0.00013878\n",
      "[600]\ttraining's l2: 0.000104413\tvalid_1's l2: 0.000125338\n",
      "[800]\ttraining's l2: 9.67709e-05\tvalid_1's l2: 0.000119808\n",
      "[1000]\ttraining's l2: 9.19728e-05\tvalid_1's l2: 0.000117385\n",
      "[1200]\ttraining's l2: 8.85649e-05\tvalid_1's l2: 0.000115529\n",
      "[1400]\ttraining's l2: 8.59221e-05\tvalid_1's l2: 0.00011439\n",
      "[1600]\ttraining's l2: 8.37249e-05\tvalid_1's l2: 0.000113813\n",
      "[1800]\ttraining's l2: 8.18084e-05\tvalid_1's l2: 0.000113434\n",
      "[2000]\ttraining's l2: 8.01e-05\tvalid_1's l2: 0.000113093\n",
      "[2200]\ttraining's l2: 7.86521e-05\tvalid_1's l2: 0.000112715\n",
      "[2400]\ttraining's l2: 7.73049e-05\tvalid_1's l2: 0.000112263\n",
      "[2600]\ttraining's l2: 7.62526e-05\tvalid_1's l2: 0.000111916\n",
      "Early stopping, best iteration is:\n",
      "[2566]\ttraining's l2: 7.63346e-05\tvalid_1's l2: 0.000111854\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000175163\tvalid_1's l2: 0.000176079\n",
      "[400]\ttraining's l2: 0.000119093\tvalid_1's l2: 0.000126564\n",
      "[600]\ttraining's l2: 0.000102642\tvalid_1's l2: 0.000115523\n",
      "[800]\ttraining's l2: 9.53415e-05\tvalid_1's l2: 0.000111613\n",
      "[1000]\ttraining's l2: 9.07785e-05\tvalid_1's l2: 0.000109374\n",
      "[1200]\ttraining's l2: 8.75946e-05\tvalid_1's l2: 0.000107861\n",
      "[1400]\ttraining's l2: 8.49268e-05\tvalid_1's l2: 0.000107022\n",
      "[1600]\ttraining's l2: 8.28656e-05\tvalid_1's l2: 0.000106453\n",
      "[1800]\ttraining's l2: 8.11564e-05\tvalid_1's l2: 0.000105958\n",
      "[2000]\ttraining's l2: 7.95757e-05\tvalid_1's l2: 0.000105489\n",
      "[2200]\ttraining's l2: 7.81424e-05\tvalid_1's l2: 0.000105248\n",
      "[2400]\ttraining's l2: 7.73732e-05\tvalid_1's l2: 0.000105154\n",
      "Early stopping, best iteration is:\n",
      "[2302]\ttraining's l2: 7.74695e-05\tvalid_1's l2: 0.000105142\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000168496\tvalid_1's l2: 0.000234409\n",
      "[400]\ttraining's l2: 0.000110996\tvalid_1's l2: 0.000183472\n",
      "[600]\ttraining's l2: 9.56917e-05\tvalid_1's l2: 0.000167006\n",
      "[800]\ttraining's l2: 8.84853e-05\tvalid_1's l2: 0.000160035\n",
      "[1000]\ttraining's l2: 8.41769e-05\tvalid_1's l2: 0.000156558\n",
      "[1200]\ttraining's l2: 8.11031e-05\tvalid_1's l2: 0.000154017\n",
      "[1400]\ttraining's l2: 7.85743e-05\tvalid_1's l2: 0.000152728\n",
      "[1600]\ttraining's l2: 7.6518e-05\tvalid_1's l2: 0.000151621\n",
      "[1800]\ttraining's l2: 7.48233e-05\tvalid_1's l2: 0.000150806\n",
      "[2000]\ttraining's l2: 7.31894e-05\tvalid_1's l2: 0.00015035\n",
      "[2200]\ttraining's l2: 7.18595e-05\tvalid_1's l2: 0.000149797\n",
      "Early stopping, best iteration is:\n",
      "[2194]\ttraining's l2: 7.18947e-05\tvalid_1's l2: 0.000149766\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000172205\tvalid_1's l2: 0.000169647\n",
      "[400]\ttraining's l2: 0.000117514\tvalid_1's l2: 0.000139505\n",
      "[600]\ttraining's l2: 0.000100592\tvalid_1's l2: 0.000131928\n",
      "[800]\ttraining's l2: 9.30604e-05\tvalid_1's l2: 0.000129746\n",
      "[1000]\ttraining's l2: 8.84859e-05\tvalid_1's l2: 0.000128946\n",
      "[1200]\ttraining's l2: 8.51044e-05\tvalid_1's l2: 0.000128674\n",
      "Early stopping, best iteration is:\n",
      "[1117]\ttraining's l2: 8.6348e-05\tvalid_1's l2: 0.00012861\n",
      "CV score: 0.00012472\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 300,\n",
    "         'min_data_in_leaf': 12, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8,\n",
    "         \"bagging_seed\": 6,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:0.424062\tvalid_data-rmse:0.423535\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.314519\tvalid_data-rmse:0.313953\n",
      "[200]\ttrain-rmse:0.233443\tvalid_data-rmse:0.232877\n",
      "[300]\ttrain-rmse:0.173455\tvalid_data-rmse:0.17296\n",
      "[400]\ttrain-rmse:0.129094\tvalid_data-rmse:0.128722\n",
      "[500]\ttrain-rmse:0.09629\tvalid_data-rmse:0.096041\n",
      "[600]\ttrain-rmse:0.072074\tvalid_data-rmse:0.071964\n",
      "[700]\ttrain-rmse:0.054209\tvalid_data-rmse:0.054299\n",
      "[800]\ttrain-rmse:0.041002\tvalid_data-rmse:0.04136\n",
      "[900]\ttrain-rmse:0.031284\tvalid_data-rmse:0.031998\n",
      "[1000]\ttrain-rmse:0.024127\tvalid_data-rmse:0.02526\n",
      "[1100]\ttrain-rmse:0.018893\tvalid_data-rmse:0.020482\n",
      "[1200]\ttrain-rmse:0.015047\tvalid_data-rmse:0.017178\n",
      "[1300]\ttrain-rmse:0.012253\tvalid_data-rmse:0.014976\n",
      "[1400]\ttrain-rmse:0.01024\tvalid_data-rmse:0.013534\n",
      "[1500]\ttrain-rmse:0.008761\tvalid_data-rmse:0.012604\n",
      "[1600]\ttrain-rmse:0.007689\tvalid_data-rmse:0.012013\n",
      "[1700]\ttrain-rmse:0.006925\tvalid_data-rmse:0.011626\n",
      "[1800]\ttrain-rmse:0.006361\tvalid_data-rmse:0.011387\n",
      "[1900]\ttrain-rmse:0.005953\tvalid_data-rmse:0.011234\n",
      "[2000]\ttrain-rmse:0.005631\tvalid_data-rmse:0.011136\n",
      "[2100]\ttrain-rmse:0.005386\tvalid_data-rmse:0.011069\n",
      "[2200]\ttrain-rmse:0.005159\tvalid_data-rmse:0.011022\n",
      "[2300]\ttrain-rmse:0.004968\tvalid_data-rmse:0.010985\n",
      "[2400]\ttrain-rmse:0.004802\tvalid_data-rmse:0.010959\n",
      "[2500]\ttrain-rmse:0.00465\tvalid_data-rmse:0.010947\n",
      "[2600]\ttrain-rmse:0.004518\tvalid_data-rmse:0.010936\n",
      "[2700]\ttrain-rmse:0.004383\tvalid_data-rmse:0.010924\n",
      "[2800]\ttrain-rmse:0.004245\tvalid_data-rmse:0.01092\n",
      "[2900]\ttrain-rmse:0.004118\tvalid_data-rmse:0.010916\n",
      "[3000]\ttrain-rmse:0.003992\tvalid_data-rmse:0.010913\n",
      "[3100]\ttrain-rmse:0.00388\tvalid_data-rmse:0.010907\n",
      "[3200]\ttrain-rmse:0.003776\tvalid_data-rmse:0.010905\n",
      "[3300]\ttrain-rmse:0.003669\tvalid_data-rmse:0.010909\n",
      "Stopping. Best iteration:\n",
      "[3108]\ttrain-rmse:0.003872\tvalid_data-rmse:0.010905\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:0.424435\tvalid_data-rmse:0.422029\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.314794\tvalid_data-rmse:0.31256\n",
      "[200]\ttrain-rmse:0.233649\tvalid_data-rmse:0.231554\n",
      "[300]\ttrain-rmse:0.173626\tvalid_data-rmse:0.171661\n",
      "[400]\ttrain-rmse:0.129232\tvalid_data-rmse:0.127407\n",
      "[500]\ttrain-rmse:0.096412\tvalid_data-rmse:0.094722\n",
      "[600]\ttrain-rmse:0.072175\tvalid_data-rmse:0.070574\n",
      "[700]\ttrain-rmse:0.05429\tvalid_data-rmse:0.052817\n",
      "[800]\ttrain-rmse:0.041102\tvalid_data-rmse:0.039803\n",
      "[900]\ttrain-rmse:0.031378\tvalid_data-rmse:0.030312\n",
      "[1000]\ttrain-rmse:0.024222\tvalid_data-rmse:0.023489\n",
      "[1100]\ttrain-rmse:0.018977\tvalid_data-rmse:0.018708\n",
      "[1200]\ttrain-rmse:0.015127\tvalid_data-rmse:0.015461\n",
      "[1300]\ttrain-rmse:0.012324\tvalid_data-rmse:0.013359\n",
      "[1400]\ttrain-rmse:0.010275\tvalid_data-rmse:0.012088\n",
      "[1500]\ttrain-rmse:0.008789\tvalid_data-rmse:0.011351\n",
      "[1600]\ttrain-rmse:0.007716\tvalid_data-rmse:0.010953\n",
      "[1700]\ttrain-rmse:0.006956\tvalid_data-rmse:0.010754\n",
      "[1800]\ttrain-rmse:0.006381\tvalid_data-rmse:0.010672\n",
      "[1900]\ttrain-rmse:0.005969\tvalid_data-rmse:0.010653\n",
      "[2000]\ttrain-rmse:0.005644\tvalid_data-rmse:0.01067\n",
      "Stopping. Best iteration:\n",
      "[1877]\ttrain-rmse:0.006053\tvalid_data-rmse:0.010653\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:0.42331\tvalid_data-rmse:0.426535\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.313966\tvalid_data-rmse:0.316914\n",
      "[200]\ttrain-rmse:0.233038\tvalid_data-rmse:0.235692\n",
      "[300]\ttrain-rmse:0.173181\tvalid_data-rmse:0.175447\n",
      "[400]\ttrain-rmse:0.128873\tvalid_data-rmse:0.130826\n",
      "[500]\ttrain-rmse:0.096134\tvalid_data-rmse:0.097818\n",
      "[600]\ttrain-rmse:0.071979\tvalid_data-rmse:0.073399\n",
      "[700]\ttrain-rmse:0.054158\tvalid_data-rmse:0.055299\n",
      "[800]\ttrain-rmse:0.040983\tvalid_data-rmse:0.041897\n",
      "[900]\ttrain-rmse:0.031276\tvalid_data-rmse:0.032082\n",
      "[1000]\ttrain-rmse:0.024144\tvalid_data-rmse:0.02499\n",
      "[1100]\ttrain-rmse:0.018918\tvalid_data-rmse:0.019952\n",
      "[1200]\ttrain-rmse:0.015067\tvalid_data-rmse:0.016459\n",
      "[1300]\ttrain-rmse:0.01227\tvalid_data-rmse:0.014173\n",
      "[1400]\ttrain-rmse:0.010209\tvalid_data-rmse:0.012724\n",
      "[1500]\ttrain-rmse:0.008729\tvalid_data-rmse:0.011862\n",
      "[1600]\ttrain-rmse:0.007658\tvalid_data-rmse:0.011372\n",
      "[1700]\ttrain-rmse:0.006873\tvalid_data-rmse:0.011111\n",
      "[1800]\ttrain-rmse:0.006303\tvalid_data-rmse:0.010994\n",
      "[1900]\ttrain-rmse:0.00587\tvalid_data-rmse:0.010939\n",
      "[2000]\ttrain-rmse:0.005546\tvalid_data-rmse:0.010927\n",
      "[2100]\ttrain-rmse:0.005282\tvalid_data-rmse:0.010932\n",
      "Stopping. Best iteration:\n",
      "[1997]\ttrain-rmse:0.005556\tvalid_data-rmse:0.010926\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:0.423435\tvalid_data-rmse:0.426054\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.314043\tvalid_data-rmse:0.316751\n",
      "[200]\ttrain-rmse:0.233095\tvalid_data-rmse:0.23577\n",
      "[300]\ttrain-rmse:0.173191\tvalid_data-rmse:0.175702\n",
      "[400]\ttrain-rmse:0.128885\tvalid_data-rmse:0.131089\n",
      "[500]\ttrain-rmse:0.096135\tvalid_data-rmse:0.098067\n",
      "[600]\ttrain-rmse:0.071957\tvalid_data-rmse:0.073722\n",
      "[700]\ttrain-rmse:0.054088\tvalid_data-rmse:0.055798\n",
      "[800]\ttrain-rmse:0.040897\tvalid_data-rmse:0.042662\n",
      "[900]\ttrain-rmse:0.031148\tvalid_data-rmse:0.03306\n",
      "[1000]\ttrain-rmse:0.023975\tvalid_data-rmse:0.026169\n",
      "[1100]\ttrain-rmse:0.018717\tvalid_data-rmse:0.02131\n",
      "[1200]\ttrain-rmse:0.014846\tvalid_data-rmse:0.017948\n",
      "[1300]\ttrain-rmse:0.012026\tvalid_data-rmse:0.015748\n",
      "[1400]\ttrain-rmse:0.009953\tvalid_data-rmse:0.014333\n",
      "[1500]\ttrain-rmse:0.008467\tvalid_data-rmse:0.013473\n",
      "[1600]\ttrain-rmse:0.007374\tvalid_data-rmse:0.012964\n",
      "[1700]\ttrain-rmse:0.006591\tvalid_data-rmse:0.01267\n",
      "[1800]\ttrain-rmse:0.006036\tvalid_data-rmse:0.012505\n",
      "[1900]\ttrain-rmse:0.005615\tvalid_data-rmse:0.012409\n",
      "[2000]\ttrain-rmse:0.005284\tvalid_data-rmse:0.012354\n",
      "[2100]\ttrain-rmse:0.005022\tvalid_data-rmse:0.012333\n",
      "[2200]\ttrain-rmse:0.00481\tvalid_data-rmse:0.012321\n",
      "[2300]\ttrain-rmse:0.00461\tvalid_data-rmse:0.012322\n",
      "Stopping. Best iteration:\n",
      "[2197]\ttrain-rmse:0.004815\tvalid_data-rmse:0.01232\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:0.42454\tvalid_data-rmse:0.421608\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.314885\tvalid_data-rmse:0.312024\n",
      "[200]\ttrain-rmse:0.233734\tvalid_data-rmse:0.231105\n",
      "[300]\ttrain-rmse:0.173708\tvalid_data-rmse:0.171494\n",
      "[400]\ttrain-rmse:0.129289\tvalid_data-rmse:0.127476\n",
      "[500]\ttrain-rmse:0.096459\tvalid_data-rmse:0.09501\n",
      "[600]\ttrain-rmse:0.072213\tvalid_data-rmse:0.071084\n",
      "[700]\ttrain-rmse:0.054318\tvalid_data-rmse:0.053552\n",
      "[800]\ttrain-rmse:0.041086\tvalid_data-rmse:0.040756\n",
      "[900]\ttrain-rmse:0.031327\tvalid_data-rmse:0.03147\n",
      "[1000]\ttrain-rmse:0.024147\tvalid_data-rmse:0.024794\n",
      "[1100]\ttrain-rmse:0.018872\tvalid_data-rmse:0.0201\n",
      "[1200]\ttrain-rmse:0.014995\tvalid_data-rmse:0.016892\n",
      "[1300]\ttrain-rmse:0.012155\tvalid_data-rmse:0.014777\n",
      "[1400]\ttrain-rmse:0.010082\tvalid_data-rmse:0.013401\n",
      "[1500]\ttrain-rmse:0.008558\tvalid_data-rmse:0.01254\n",
      "[1600]\ttrain-rmse:0.007463\tvalid_data-rmse:0.012022\n",
      "[1700]\ttrain-rmse:0.006666\tvalid_data-rmse:0.011709\n",
      "[1800]\ttrain-rmse:0.006088\tvalid_data-rmse:0.01152\n",
      "[1900]\ttrain-rmse:0.005664\tvalid_data-rmse:0.011422\n",
      "[2000]\ttrain-rmse:0.005325\tvalid_data-rmse:0.011364\n",
      "[2100]\ttrain-rmse:0.005064\tvalid_data-rmse:0.011335\n",
      "[2200]\ttrain-rmse:0.004848\tvalid_data-rmse:0.011327\n",
      "[2300]\ttrain-rmse:0.004665\tvalid_data-rmse:0.01132\n",
      "[2400]\ttrain-rmse:0.004499\tvalid_data-rmse:0.01133\n",
      "[2500]\ttrain-rmse:0.004363\tvalid_data-rmse:0.011337\n",
      "Stopping. Best iteration:\n",
      "[2302]\ttrain-rmse:0.00466\tvalid_data-rmse:0.011319\n",
      "\n",
      "CV score: 0.00012634\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'eta': 0.003, 'max_depth': 12, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 4}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "oof_xgb = np.zeros(len(train))\n",
    "predictions_xgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=100, params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(X_train[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00012074397189393701"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack = np.vstack([oof_lgb,oof_xgb]).transpose()\n",
    "test_stack = np.vstack([predictions_lgb, predictions_xgb]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=4590)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    clf_3 = BayesianRidge()\n",
    "    clf_3.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack[val_idx] = clf_3.predict(val_data)\n",
    "    predictions += clf_3.predict(test_stack) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('jinnan_round1_submit_20181227.csv', header=None)\n",
    "sub_df[1] = predictions\n",
    "sub_df[1] = sub_df[1].apply(lambda x:round(x, 3))\n",
    "sub_df.to_csv(\"submit.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
