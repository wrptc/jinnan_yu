{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jinnan.ipynb                       jinnan_round1_testA_20181227.csv  submit.csv\r\n",
      "jinnan_round1_submit_20181227.csv  jinnan_round1_train_20181227.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('jinnan_round1_train_20181227.csv', encoding = 'gb18030')\n",
    "test  = pd.read_csv('jinnan_round1_testA_20181227.csv', encoding = 'gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>样本id</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "      <th>A17</th>\n",
       "      <th>A18</th>\n",
       "      <th>A19</th>\n",
       "      <th>A20</th>\n",
       "      <th>A21</th>\n",
       "      <th>A22</th>\n",
       "      <th>A23</th>\n",
       "      <th>A24</th>\n",
       "      <th>A25</th>\n",
       "      <th>A26</th>\n",
       "      <th>A27</th>\n",
       "      <th>A28</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B9</th>\n",
       "      <th>B10</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>B13</th>\n",
       "      <th>B14</th>\n",
       "      <th>收率</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_1528</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:30:00</td>\n",
       "      <td>100</td>\n",
       "      <td>16:30:00</td>\n",
       "      <td>102</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>21:00-21:30</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>75</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>70</td>\n",
       "      <td>6:30-7:00</td>\n",
       "      <td>350.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7:00-8:00</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>65</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11:30-13:00</td>\n",
       "      <td>14:00-15:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>400</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1698</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>101</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>19:00-20:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>73</td>\n",
       "      <td>21:00-22:00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22:00-23:00</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>6:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6:00-7:30</td>\n",
       "      <td>7:30-9:00</td>\n",
       "      <td>9:00-10:00</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>400</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_639</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>102</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>19:00-19:30</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>79</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>73</td>\n",
       "      <td>21:00-22:00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22:00-23:00</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>1:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1:00-2:30</td>\n",
       "      <td>2:30-4:00</td>\n",
       "      <td>4:00-5:00</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>400</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_483</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>1:30:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>102</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5:00:00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>6:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>6:30-7:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7:30:00</td>\n",
       "      <td>70</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>78</td>\n",
       "      <td>13:30-14:30</td>\n",
       "      <td>290.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>14:30-15:30</td>\n",
       "      <td>15:30:00</td>\n",
       "      <td>65</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>19:00-20:30</td>\n",
       "      <td>21:30-23:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>400</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_617</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>101</td>\n",
       "      <td>1:00:00</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>3:00-4:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>5:00:00</td>\n",
       "      <td>73</td>\n",
       "      <td>5:00-6:00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6:00-7:00</td>\n",
       "      <td>7:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>9:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9:00-10:30</td>\n",
       "      <td>10:30-12:00</td>\n",
       "      <td>12:00-13:00</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>420</td>\n",
       "      <td>0.983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          样本id   A1  A2     A3   A4        A5    A6   A7  A8        A9  A10  \\\n",
       "0  sample_1528  300 NaN  405.0  700  13:30:00  38.0  NaN NaN  15:30:00  100   \n",
       "1  sample_1698  300 NaN  405.0  700  14:00:00  29.0  NaN NaN  16:00:00  101   \n",
       "2   sample_639  300 NaN  405.0  700  14:00:00  29.0  NaN NaN  16:00:00  102   \n",
       "3   sample_483  300 NaN  405.0  700   1:30:00  38.0  NaN NaN   3:00:00  100   \n",
       "4   sample_617  300 NaN  405.0  700  22:00:00  29.0  NaN NaN   0:00:00  101   \n",
       "\n",
       "        A11  A12  A13       A14    A15       A16    A17  A18  A19  \\\n",
       "0  16:30:00  102  0.2  17:30:00  103.0  18:30:00  104.0  0.2  300   \n",
       "1  17:00:00  103  0.2  18:00:00  104.0  19:00:00  105.0  0.2  200   \n",
       "2  17:00:00  103  0.2  18:00:00  104.0  19:00:00  105.0  0.2  200   \n",
       "3   4:00:00  102  0.2   5:00:00  103.0   6:00:00  104.0  0.2  200   \n",
       "4   1:00:00  103  0.2   2:00:00  104.0   3:00:00  105.0  0.2  200   \n",
       "\n",
       "           A20   A21   A22  A23       A24 A25       A26  A27          A28  \\\n",
       "0  21:00-21:30  50.0   9.0  5.0  22:00:00  75  22:30:00   70    6:30-7:00   \n",
       "1  19:00-20:00  50.0   9.0  5.0  20:00:00  80  21:00:00   73  21:00-22:00   \n",
       "2  19:00-19:30  50.0   9.0  5.0  20:00:00  79  21:00:00   73  21:00-22:00   \n",
       "3    6:30-7:00  50.0  10.0  5.0   7:30:00  70   8:00:00   78  13:30-14:30   \n",
       "4    3:00-4:00  50.0   9.0  5.0   4:00:00  80   5:00:00   73    5:00-6:00   \n",
       "\n",
       "      B1   B2   B3           B4        B5  B6        B7    B8           B9  \\\n",
       "0  350.0  3.5  3.5    7:00-8:00   8:00:00  65  11:30:00  45.0  11:30-13:00   \n",
       "1  320.0  3.5  3.5  22:00-23:00  23:00:00  80   6:00:00  45.0    6:00-7:30   \n",
       "2  320.0  3.5  3.5  22:00-23:00  23:00:00  80   1:00:00  45.0    1:00-2:30   \n",
       "3  290.0  3.5  3.5  14:30-15:30  15:30:00  65  18:00:00  45.0  19:00-20:30   \n",
       "4  320.0  3.5  3.5    6:00-7:00   7:00:00  80   9:00:00  45.0   9:00-10:30   \n",
       "\n",
       "           B10          B11     B12   B13  B14     收率  \n",
       "0  14:00-15:30          NaN   800.0  0.15  400  0.879  \n",
       "1    7:30-9:00   9:00-10:00  1200.0  0.15  400  0.902  \n",
       "2    2:30-4:00    4:00-5:00  1200.0  0.15  400  0.936  \n",
       "3  21:30-23:00          NaN   800.0  0.15  400  0.902  \n",
       "4  10:30-12:00  12:00-13:00  1200.0  0.15  420  0.983  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 删除缺失率超过90%的列\n",
    "good_cols = list(train.columns)\n",
    "for col in train.columns:\n",
    "    rate = train[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "    if rate > 0.9:\n",
    "        good_cols.remove(col)\n",
    "\n",
    "# # 删除异常值\n",
    "train = train[train['收率']>0.86]\n",
    "        \n",
    "train = train[good_cols]\n",
    "good_cols.remove('收率')\n",
    "test  = test[good_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并数据集\n",
    "target = train['收率']\n",
    "del train['收率']\n",
    "data = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "data = data.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeTranSecond(t):\n",
    "    try:\n",
    "        t,m,s=t.split(\":\")\n",
    "    except:\n",
    "        if t=='1900/1/9 7:00':\n",
    "            return 7*3600/3600\n",
    "        elif t=='1900/1/1 2:30':\n",
    "            return (2*3600+30*60)/3600\n",
    "        elif t==-1:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    try:\n",
    "        tm = (int(t)*3600+int(m)*60+int(s))/3600\n",
    "    except:\n",
    "        return (30*60)/3600\n",
    "    \n",
    "    return tm\n",
    "for f in ['A5','A7','A9','A11','A14','A16','A24','A26','B5','B7']:\n",
    "    data[f] = data[f].apply(timeTranSecond)\n",
    "\n",
    "def getDuration(se):\n",
    "    try:\n",
    "        sh,sm,eh,em=re.findall(r\"\\d+\\.?\\d*\",se)\n",
    "    except:\n",
    "        if se == -1:\n",
    "            return -1 \n",
    "        \n",
    "    try:\n",
    "        if int(sh)>int(eh):\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600 + 24\n",
    "        else:\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600\n",
    "    except:\n",
    "        if se=='19:-20:05':\n",
    "            return 1\n",
    "        elif se=='15:00-1600':\n",
    "            return 1\n",
    "    \n",
    "    return tm\n",
    "\n",
    "def get_start(se):\n",
    "    try:\n",
    "        sh, sm, eh, em = re.findall(r'\\d+\\.?d*', se)\n",
    "    except:\n",
    "        if se == -1:\n",
    "            return -1\n",
    "    try:\n",
    "        tm = (int(eh) * 3600 + int(em) * 60)/3600\n",
    "    except:\n",
    "        if se == '19:-20:05':\n",
    "            return 19\n",
    "        elif se == '15:00-1600':\n",
    "            return 15\n",
    "    return tm\n",
    "for f in ['A20','A28','B4','B9','B10','B11']:\n",
    "    data[f+'_'] = data.apply(lambda df: getDuration(df[f]), axis=1)\n",
    "for f in ['A20','A28','B4','B9','B10','B11']:\n",
    "    data[f] = data.apply(lambda df: get_start(df[f]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_point_cols = ['A5','A7','A9','A11','A14','A16','A20', 'A24','A26','A28','B4','B5','B7','B9','B10','B11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in range(len(time_point_cols)-1):\n",
    "    _, tmp = divmod(data[time_point_cols[col+1]] - data[time_point_cols[col]], 24)\n",
    "    data[time_point_cols[col+1]+'-'+time_point_cols[col]] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_columns = [f for f in data.columns if f != '样本id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_float(x):\n",
    "    try:\n",
    "        return(float(x))\n",
    "    except:\n",
    "        return 70  \n",
    "for f in cate_columns:\n",
    "    data[f] = data[f].apply(lambda x: get_float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_spy = data[:train.shape[0]]\n",
    "corr_spy['target'] = list(target)\n",
    "th = sorted(list(corr_spy.corr().target.abs()),reverse=True)[int(len(corr_spy.columns)*0.88)]\n",
    "cate_columns = []\n",
    "for col in corr_spy.corr().columns:\n",
    "    if corr_spy.corr()['target'][col] >= th:\n",
    "        cate_columns.append(col)\n",
    "cate_columns.remove('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoder\n",
    "for f in cate_columns:\n",
    "    data[f] = data[f].map(dict(zip(data[f].unique(), range(0, data[f].nunique()))))\n",
    "train = data[:train.shape[0]]\n",
    "test  = data[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'] = list(target)\n",
    "train['intTarget'] = pd.cut(train['target'], 6, labels=False)\n",
    "train = pd.get_dummies(train, columns=['intTarget'])\n",
    "li = train.columns[-6:]\n",
    "mean_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f1 in cate_columns:\n",
    "    for f2 in li:\n",
    "        col_name = f1+\"_\"+f2+'_mean'\n",
    "        mean_features.append(col_name)\n",
    "        order_label = train.groupby([f1])[f2].mean()\n",
    "        for df in [train, test]:\n",
    "            df[col_name] = df[f1].map(order_label)\n",
    "\n",
    "train.drop(li, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['样本id','target'], axis=1, inplace=True)\n",
    "test = test[train.columns]\n",
    "X_train = train.values\n",
    "y_train = target.values\n",
    "X_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000159544\tvalid_1's l2: 0.000177768\n",
      "[400]\ttraining's l2: 0.00012653\tvalid_1's l2: 0.000160618\n",
      "[600]\ttraining's l2: 0.000113864\tvalid_1's l2: 0.000156493\n",
      "Early stopping, best iteration is:\n",
      "[685]\ttraining's l2: 0.000110336\tvalid_1's l2: 0.000155963\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000156141\tvalid_1's l2: 0.000176597\n",
      "[400]\ttraining's l2: 0.000121958\tvalid_1's l2: 0.000166124\n",
      "Early stopping, best iteration is:\n",
      "[386]\ttraining's l2: 0.000123185\tvalid_1's l2: 0.000165993\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000154086\tvalid_1's l2: 0.000199695\n",
      "[400]\ttraining's l2: 0.000121447\tvalid_1's l2: 0.000176623\n",
      "[600]\ttraining's l2: 0.000109315\tvalid_1's l2: 0.000172056\n",
      "[800]\ttraining's l2: 0.000102288\tvalid_1's l2: 0.00017033\n",
      "[1000]\ttraining's l2: 9.72238e-05\tvalid_1's l2: 0.00016898\n",
      "[1200]\ttraining's l2: 9.36075e-05\tvalid_1's l2: 0.000168989\n",
      "Early stopping, best iteration is:\n",
      "[1157]\ttraining's l2: 9.42986e-05\tvalid_1's l2: 0.000168638\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.0001481\tvalid_1's l2: 0.000208945\n",
      "[400]\ttraining's l2: 0.000118604\tvalid_1's l2: 0.0001976\n",
      "[600]\ttraining's l2: 0.000107284\tvalid_1's l2: 0.000194776\n",
      "[800]\ttraining's l2: 0.000100898\tvalid_1's l2: 0.000193757\n",
      "[1000]\ttraining's l2: 9.65292e-05\tvalid_1's l2: 0.000193331\n",
      "[1200]\ttraining's l2: 9.32757e-05\tvalid_1's l2: 0.000192498\n",
      "Early stopping, best iteration is:\n",
      "[1226]\ttraining's l2: 9.29012e-05\tvalid_1's l2: 0.0001922\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000155489\tvalid_1's l2: 0.000210234\n",
      "[400]\ttraining's l2: 0.000124437\tvalid_1's l2: 0.000191252\n",
      "[600]\ttraining's l2: 0.000113672\tvalid_1's l2: 0.00018805\n",
      "[800]\ttraining's l2: 0.000107239\tvalid_1's l2: 0.000186795\n",
      "Early stopping, best iteration is:\n",
      "[786]\ttraining's l2: 0.000107591\tvalid_1's l2: 0.000186697\n",
      "CV score: 0.00017389\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 120,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.02,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:0.422659\tvalid_data-rmse:0.423392\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256808\tvalid_data-rmse:0.257666\n",
      "[200]\ttrain-rmse:0.156463\tvalid_data-rmse:0.157249\n",
      "[300]\ttrain-rmse:0.095833\tvalid_data-rmse:0.096683\n",
      "[400]\ttrain-rmse:0.059334\tvalid_data-rmse:0.060381\n",
      "[500]\ttrain-rmse:0.037499\tvalid_data-rmse:0.038804\n",
      "[600]\ttrain-rmse:0.02455\tvalid_data-rmse:0.026305\n",
      "[700]\ttrain-rmse:0.016975\tvalid_data-rmse:0.019354\n",
      "[800]\ttrain-rmse:0.012608\tvalid_data-rmse:0.015716\n",
      "[900]\ttrain-rmse:0.010152\tvalid_data-rmse:0.013926\n",
      "[1000]\ttrain-rmse:0.008784\tvalid_data-rmse:0.013097\n",
      "[1100]\ttrain-rmse:0.008\tvalid_data-rmse:0.012726\n",
      "[1200]\ttrain-rmse:0.007511\tvalid_data-rmse:0.012579\n",
      "[1300]\ttrain-rmse:0.00717\tvalid_data-rmse:0.012546\n",
      "[1400]\ttrain-rmse:0.006916\tvalid_data-rmse:0.012572\n",
      "Stopping. Best iteration:\n",
      "[1283]\ttrain-rmse:0.007219\tvalid_data-rmse:0.012541\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:0.42256\tvalid_data-rmse:0.423793\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256752\tvalid_data-rmse:0.257865\n",
      "[200]\ttrain-rmse:0.156416\tvalid_data-rmse:0.15748\n",
      "[300]\ttrain-rmse:0.095782\tvalid_data-rmse:0.09685\n",
      "[400]\ttrain-rmse:0.059265\tvalid_data-rmse:0.060308\n",
      "[500]\ttrain-rmse:0.037414\tvalid_data-rmse:0.038541\n",
      "[600]\ttrain-rmse:0.024451\tvalid_data-rmse:0.026045\n",
      "[700]\ttrain-rmse:0.016856\tvalid_data-rmse:0.01919\n",
      "[800]\ttrain-rmse:0.012533\tvalid_data-rmse:0.015711\n",
      "[900]\ttrain-rmse:0.010092\tvalid_data-rmse:0.014089\n",
      "[1000]\ttrain-rmse:0.008767\tvalid_data-rmse:0.013371\n",
      "[1100]\ttrain-rmse:0.008017\tvalid_data-rmse:0.013062\n",
      "[1200]\ttrain-rmse:0.007543\tvalid_data-rmse:0.012954\n",
      "[1300]\ttrain-rmse:0.00724\tvalid_data-rmse:0.01292\n",
      "[1400]\ttrain-rmse:0.006999\tvalid_data-rmse:0.012937\n",
      "[1500]\ttrain-rmse:0.00682\tvalid_data-rmse:0.012974\n",
      "Stopping. Best iteration:\n",
      "[1311]\ttrain-rmse:0.00721\tvalid_data-rmse:0.012917\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:0.422689\tvalid_data-rmse:0.423268\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.25683\tvalid_data-rmse:0.256725\n",
      "[200]\ttrain-rmse:0.156451\tvalid_data-rmse:0.155979\n",
      "[300]\ttrain-rmse:0.095818\tvalid_data-rmse:0.094947\n",
      "[400]\ttrain-rmse:0.059277\tvalid_data-rmse:0.058272\n",
      "[500]\ttrain-rmse:0.037418\tvalid_data-rmse:0.036757\n",
      "[600]\ttrain-rmse:0.024439\tvalid_data-rmse:0.02458\n",
      "[700]\ttrain-rmse:0.016849\tvalid_data-rmse:0.018067\n",
      "[800]\ttrain-rmse:0.01251\tvalid_data-rmse:0.014847\n",
      "[900]\ttrain-rmse:0.0101\tvalid_data-rmse:0.013369\n",
      "[1000]\ttrain-rmse:0.008802\tvalid_data-rmse:0.012755\n",
      "[1100]\ttrain-rmse:0.008071\tvalid_data-rmse:0.012501\n",
      "[1200]\ttrain-rmse:0.00762\tvalid_data-rmse:0.012402\n",
      "[1300]\ttrain-rmse:0.007297\tvalid_data-rmse:0.012366\n",
      "[1400]\ttrain-rmse:0.00707\tvalid_data-rmse:0.012354\n",
      "[1500]\ttrain-rmse:0.006892\tvalid_data-rmse:0.012365\n",
      "[1600]\ttrain-rmse:0.006749\tvalid_data-rmse:0.01236\n",
      "Stopping. Best iteration:\n",
      "[1411]\ttrain-rmse:0.007049\tvalid_data-rmse:0.012351\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:0.423129\tvalid_data-rmse:0.421506\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.257082\tvalid_data-rmse:0.255825\n",
      "[200]\ttrain-rmse:0.156619\tvalid_data-rmse:0.155464\n",
      "[300]\ttrain-rmse:0.095881\tvalid_data-rmse:0.0949\n",
      "[400]\ttrain-rmse:0.059286\tvalid_data-rmse:0.058619\n",
      "[500]\ttrain-rmse:0.037403\tvalid_data-rmse:0.037302\n",
      "[600]\ttrain-rmse:0.024448\tvalid_data-rmse:0.025286\n",
      "[700]\ttrain-rmse:0.016856\tvalid_data-rmse:0.018957\n",
      "[800]\ttrain-rmse:0.012486\tvalid_data-rmse:0.016002\n",
      "[900]\ttrain-rmse:0.010033\tvalid_data-rmse:0.014748\n",
      "[1000]\ttrain-rmse:0.008665\tvalid_data-rmse:0.014265\n",
      "[1100]\ttrain-rmse:0.007884\tvalid_data-rmse:0.0141\n",
      "[1200]\ttrain-rmse:0.007412\tvalid_data-rmse:0.014056\n",
      "[1300]\ttrain-rmse:0.007083\tvalid_data-rmse:0.014079\n",
      "[1400]\ttrain-rmse:0.006853\tvalid_data-rmse:0.014109\n",
      "Stopping. Best iteration:\n",
      "[1218]\ttrain-rmse:0.007349\tvalid_data-rmse:0.014049\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:0.422989\tvalid_data-rmse:0.422062\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256997\tvalid_data-rmse:0.256444\n",
      "[200]\ttrain-rmse:0.156539\tvalid_data-rmse:0.156418\n",
      "[300]\ttrain-rmse:0.095817\tvalid_data-rmse:0.096019\n",
      "[400]\ttrain-rmse:0.059266\tvalid_data-rmse:0.059737\n",
      "[500]\ttrain-rmse:0.037418\tvalid_data-rmse:0.03825\n",
      "[600]\ttrain-rmse:0.024489\tvalid_data-rmse:0.025925\n",
      "[700]\ttrain-rmse:0.016949\tvalid_data-rmse:0.019305\n",
      "[800]\ttrain-rmse:0.012642\tvalid_data-rmse:0.016014\n",
      "[900]\ttrain-rmse:0.010221\tvalid_data-rmse:0.014497\n",
      "[1000]\ttrain-rmse:0.008907\tvalid_data-rmse:0.01385\n",
      "[1100]\ttrain-rmse:0.008172\tvalid_data-rmse:0.013577\n",
      "[1200]\ttrain-rmse:0.007727\tvalid_data-rmse:0.013463\n",
      "[1300]\ttrain-rmse:0.007431\tvalid_data-rmse:0.013412\n",
      "[1400]\ttrain-rmse:0.007214\tvalid_data-rmse:0.013393\n",
      "[1500]\ttrain-rmse:0.007042\tvalid_data-rmse:0.013397\n",
      "[1600]\ttrain-rmse:0.00691\tvalid_data-rmse:0.0134\n",
      "Stopping. Best iteration:\n",
      "[1417]\ttrain-rmse:0.007183\tvalid_data-rmse:0.013388\n",
      "\n",
      "CV score: 0.00017066\n"
     ]
    }
   ],
   "source": [
    "##### xgb\n",
    "xgb_params = {'n_estimators':120,'eta': 0.005, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, \n",
    "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 4}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "oof_xgb = np.zeros(len(train))\n",
    "predictions_xgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=100, params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(X_train[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0001665561300304181"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将lgb和xgb的结果进行stacking\n",
    "train_stack = np.vstack([oof_lgb,oof_xgb]).transpose()\n",
    "test_stack = np.vstack([predictions_lgb, predictions_xgb]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=666)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    clf_3 = BayesianRidge()\n",
    "    clf_3 = ARDRegression()\n",
    "    #clf_3 = LinearRegression()\n",
    "    clf_3.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack[val_idx] = clf_3.predict(val_data)\n",
    "    predictions += clf_3.predict(test_stack) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('jinnan_round1_submit_20181227.csv', header=None)\n",
    "sub_df[1] = predictions\n",
    "sub_df[1] = sub_df[1].apply(lambda x:round(x, 3))\n",
    "sub_df.to_csv(\"submit.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4291122545557169"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions ** 2).sum()/len(predictions)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
