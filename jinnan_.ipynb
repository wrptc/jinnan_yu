{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "#from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('jinnan_round1_train_20181227.csv', encoding = 'gb18030')\n",
    "test  = pd.read_csv('jinnan_round1_testA_20181227.csv', encoding = 'gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>样本id</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "      <th>A17</th>\n",
       "      <th>A18</th>\n",
       "      <th>A19</th>\n",
       "      <th>A20</th>\n",
       "      <th>A21</th>\n",
       "      <th>A22</th>\n",
       "      <th>A23</th>\n",
       "      <th>A24</th>\n",
       "      <th>A25</th>\n",
       "      <th>A26</th>\n",
       "      <th>A27</th>\n",
       "      <th>A28</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B9</th>\n",
       "      <th>B10</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>B13</th>\n",
       "      <th>B14</th>\n",
       "      <th>收率</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_1528</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:30:00</td>\n",
       "      <td>100</td>\n",
       "      <td>16:30:00</td>\n",
       "      <td>102</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>21:00-21:30</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>75</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>70</td>\n",
       "      <td>6:30-7:00</td>\n",
       "      <td>350.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7:00-8:00</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>65</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11:30-13:00</td>\n",
       "      <td>14:00-15:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>400</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1698</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>101</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>19:00-20:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>73</td>\n",
       "      <td>21:00-22:00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22:00-23:00</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>6:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6:00-7:30</td>\n",
       "      <td>7:30-9:00</td>\n",
       "      <td>9:00-10:00</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>400</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_639</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>102</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>19:00-19:30</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>79</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>73</td>\n",
       "      <td>21:00-22:00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22:00-23:00</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>1:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1:00-2:30</td>\n",
       "      <td>2:30-4:00</td>\n",
       "      <td>4:00-5:00</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>400</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_483</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>1:30:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>102</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5:00:00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>6:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>6:30-7:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7:30:00</td>\n",
       "      <td>70</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>78</td>\n",
       "      <td>13:30-14:30</td>\n",
       "      <td>290.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>14:30-15:30</td>\n",
       "      <td>15:30:00</td>\n",
       "      <td>65</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>19:00-20:30</td>\n",
       "      <td>21:30-23:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>400</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_617</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>101</td>\n",
       "      <td>1:00:00</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>3:00-4:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>5:00:00</td>\n",
       "      <td>73</td>\n",
       "      <td>5:00-6:00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6:00-7:00</td>\n",
       "      <td>7:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>9:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9:00-10:30</td>\n",
       "      <td>10:30-12:00</td>\n",
       "      <td>12:00-13:00</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>420</td>\n",
       "      <td>0.983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          样本id   A1  A2     A3   A4        A5    A6   A7  A8        A9  A10  \\\n",
       "0  sample_1528  300 NaN  405.0  700  13:30:00  38.0  NaN NaN  15:30:00  100   \n",
       "1  sample_1698  300 NaN  405.0  700  14:00:00  29.0  NaN NaN  16:00:00  101   \n",
       "2   sample_639  300 NaN  405.0  700  14:00:00  29.0  NaN NaN  16:00:00  102   \n",
       "3   sample_483  300 NaN  405.0  700   1:30:00  38.0  NaN NaN   3:00:00  100   \n",
       "4   sample_617  300 NaN  405.0  700  22:00:00  29.0  NaN NaN   0:00:00  101   \n",
       "\n",
       "        A11  A12  A13       A14    A15       A16    A17  A18  A19  \\\n",
       "0  16:30:00  102  0.2  17:30:00  103.0  18:30:00  104.0  0.2  300   \n",
       "1  17:00:00  103  0.2  18:00:00  104.0  19:00:00  105.0  0.2  200   \n",
       "2  17:00:00  103  0.2  18:00:00  104.0  19:00:00  105.0  0.2  200   \n",
       "3   4:00:00  102  0.2   5:00:00  103.0   6:00:00  104.0  0.2  200   \n",
       "4   1:00:00  103  0.2   2:00:00  104.0   3:00:00  105.0  0.2  200   \n",
       "\n",
       "           A20   A21   A22  A23       A24 A25       A26  A27          A28  \\\n",
       "0  21:00-21:30  50.0   9.0  5.0  22:00:00  75  22:30:00   70    6:30-7:00   \n",
       "1  19:00-20:00  50.0   9.0  5.0  20:00:00  80  21:00:00   73  21:00-22:00   \n",
       "2  19:00-19:30  50.0   9.0  5.0  20:00:00  79  21:00:00   73  21:00-22:00   \n",
       "3    6:30-7:00  50.0  10.0  5.0   7:30:00  70   8:00:00   78  13:30-14:30   \n",
       "4    3:00-4:00  50.0   9.0  5.0   4:00:00  80   5:00:00   73    5:00-6:00   \n",
       "\n",
       "      B1   B2   B3           B4        B5  B6        B7    B8           B9  \\\n",
       "0  350.0  3.5  3.5    7:00-8:00   8:00:00  65  11:30:00  45.0  11:30-13:00   \n",
       "1  320.0  3.5  3.5  22:00-23:00  23:00:00  80   6:00:00  45.0    6:00-7:30   \n",
       "2  320.0  3.5  3.5  22:00-23:00  23:00:00  80   1:00:00  45.0    1:00-2:30   \n",
       "3  290.0  3.5  3.5  14:30-15:30  15:30:00  65  18:00:00  45.0  19:00-20:30   \n",
       "4  320.0  3.5  3.5    6:00-7:00   7:00:00  80   9:00:00  45.0   9:00-10:30   \n",
       "\n",
       "           B10          B11     B12   B13  B14     收率  \n",
       "0  14:00-15:30          NaN   800.0  0.15  400  0.879  \n",
       "1    7:30-9:00   9:00-10:00  1200.0  0.15  400  0.902  \n",
       "2    2:30-4:00    4:00-5:00  1200.0  0.15  400  0.936  \n",
       "3  21:30-23:00          NaN   800.0  0.15  400  0.902  \n",
       "4  10:30-12:00  12:00-13:00  1200.0  0.15  420  0.983  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.624     1\n",
       "0.677     1\n",
       "0.803     1\n",
       "0.834     2\n",
       "0.846     1\n",
       "0.857     1\n",
       "0.866     1\n",
       "0.868     5\n",
       "0.870     2\n",
       "0.871     1\n",
       "0.874     3\n",
       "0.878     1\n",
       "0.879    64\n",
       "0.882     1\n",
       "0.884     2\n",
       "Name: 收率, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.收率.value_counts().sort_index().iloc[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cols = list(train.columns)\n",
    "# for col in train.columns:\n",
    "#     rate = train[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "#     if rate > 0.9:\n",
    "#         good_cols.remove(col)\n",
    "#         print(col,rate)\n",
    "\n",
    "train = train[train['收率']>0.85]\n",
    "        \n",
    "train = train[good_cols]\n",
    "good_cols.remove('收率')\n",
    "test  = test[good_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['收率']\n",
    "del train['收率']\n",
    "data = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "data = data.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeTranSecond(t):\n",
    "    try:\n",
    "        t,m,s=t.split(\":\")\n",
    "    except:\n",
    "        if t=='1900/1/9 7:00':\n",
    "            return (23*3600 + 20*60)/3600\n",
    "        elif t=='1900/1/1 2:30':\n",
    "            return (21*3600 + 30*60)/3600\n",
    "        elif t == '1900/1/21 0:00':\n",
    "            return 21\n",
    "        elif t == '1900/1/29 0:00':\n",
    "            return 14\n",
    "        elif t == '1900/1/12 0:00':\n",
    "            return 12\n",
    "        elif t == '1900/3/13 0:00':\n",
    "            return 13\n",
    "        elif t == '1900/1/22 0:00':\n",
    "            return 22\n",
    "        elif t == '700':\n",
    "            return 7\n",
    "        elif t==-1:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    try:\n",
    "        tm = (int(t)*3600+int(m)*60+int(s))/3600\n",
    "    except:\n",
    "        return (30*60)/3600\n",
    "    \n",
    "    return tm\n",
    "for f in ['A5','A7','A9','A11','A14','A16','A24','A26','B5','B7']:\n",
    "    data[f] = data[f].apply(timeTranSecond)\n",
    "\n",
    "def getDuration(se):\n",
    "    try:\n",
    "        sh,sm,eh,em=re.findall(r\"\\d+\\.?\\d*\",se)\n",
    "    except:\n",
    "        if se == -1:\n",
    "            return -1 \n",
    "        \n",
    "    try:\n",
    "        if int(sh)>int(eh):\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600 + 24\n",
    "        else:\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600\n",
    "    except:\n",
    "        if se=='19:-20:05':\n",
    "            return 1\n",
    "        elif se=='15:00-1600':\n",
    "            return 1\n",
    "    \n",
    "    return tm\n",
    "\n",
    "def get_start(se):\n",
    "    try:\n",
    "        sh, sm, eh, em = re.findall(r'\\d+\\.?d*', se)\n",
    "    except:\n",
    "        if se == -1:\n",
    "            return -1\n",
    "    try:\n",
    "        tm = (int(eh) * 3600 + int(em) * 60)/3600\n",
    "    except:\n",
    "        if se == '19:-20:05':\n",
    "            return 19\n",
    "        elif se == '15:00-1600':\n",
    "            return 15\n",
    "    return tm\n",
    "for f in ['A20','A28','B4','B9','B10','B11']:\n",
    "    data[f+'_diff'] = data.apply(lambda df: getDuration(df[f]), axis=1)\n",
    "for f in ['A20','A28','B4','B9','B10','B11']:\n",
    "    data[f] = data.apply(lambda df: get_start(df[f]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_point = ['A5','A7','A9','A11','A14','A16','A20', 'A24','A26','A28','B4','B5','B7','B9','B10','B11']\n",
    "time_period = ['A20','A28','B4','B9','B10','B11']\n",
    "\n",
    "for i, col in enumerate(time_point):\n",
    "    if i == len(time_point)-2:\n",
    "        break\n",
    "    nex_col = time_point[i+1]\n",
    "    col_name = nex_col + '-' + col\n",
    "    if col not in time_period:\n",
    "        data[col_name] = data[nex_col] - data[col]        \n",
    "    else:\n",
    "        data[col_name] = data[nex_col] - data[col] - data[col + '_diff']\n",
    "    data[col_name] = data[col_name].apply(lambda x: divmod(x, 24)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['样本id'] = data['样本id'].apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "categorical_columns = [f for f in data.columns if f not in ['样本id']]\n",
    "numerical_columns = [f for f in data.columns if f not in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>样本id</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "      <th>A17</th>\n",
       "      <th>A19</th>\n",
       "      <th>A20</th>\n",
       "      <th>A21</th>\n",
       "      <th>A22</th>\n",
       "      <th>A24</th>\n",
       "      <th>A25</th>\n",
       "      <th>A26</th>\n",
       "      <th>A27</th>\n",
       "      <th>A28</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B9</th>\n",
       "      <th>B10</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>B14</th>\n",
       "      <th>A20_diff</th>\n",
       "      <th>A28_diff</th>\n",
       "      <th>B4_diff</th>\n",
       "      <th>B9_diff</th>\n",
       "      <th>B10_diff</th>\n",
       "      <th>B11_diff</th>\n",
       "      <th>A7-A5</th>\n",
       "      <th>A9-A7</th>\n",
       "      <th>A11-A9</th>\n",
       "      <th>A14-A11</th>\n",
       "      <th>A16-A14</th>\n",
       "      <th>A20-A16</th>\n",
       "      <th>A24-A20</th>\n",
       "      <th>A26-A24</th>\n",
       "      <th>A28-A26</th>\n",
       "      <th>B4-A28</th>\n",
       "      <th>B5-B4</th>\n",
       "      <th>B7-B5</th>\n",
       "      <th>B9-B7</th>\n",
       "      <th>B10-B9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1528</td>\n",
       "      <td>300</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>13.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>100</td>\n",
       "      <td>16.5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>103.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>104.0</td>\n",
       "      <td>300</td>\n",
       "      <td>21.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>75</td>\n",
       "      <td>22.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>65</td>\n",
       "      <td>11.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>400</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1698</td>\n",
       "      <td>300</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>101</td>\n",
       "      <td>17.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>200</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>80</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>639</td>\n",
       "      <td>300</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>102</td>\n",
       "      <td>17.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>200</td>\n",
       "      <td>19.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>79</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>400</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>483</td>\n",
       "      <td>300</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>1.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>4.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>200</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>70</td>\n",
       "      <td>8.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>290.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>65</td>\n",
       "      <td>18.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>400</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>617</td>\n",
       "      <td>300</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80</td>\n",
       "      <td>5.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>80</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>420</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   样本id   A1   A2     A3   A4    A5    A6   A7   A8    A9  A10   A11    A12  \\\n",
       "0  1528  300 -1.0  405.0  700  13.5  38.0 -1.0 -1.0  15.5  100  16.5  102.0   \n",
       "1  1698  300 -1.0  405.0  700  14.0  29.0 -1.0 -1.0  16.0  101  17.0  103.0   \n",
       "2   639  300 -1.0  405.0  700  14.0  29.0 -1.0 -1.0  16.0  102  17.0  103.0   \n",
       "3   483  300 -1.0  405.0  700   1.5  38.0 -1.0 -1.0   3.0  100   4.0  102.0   \n",
       "4   617  300 -1.0  405.0  700  22.0  29.0 -1.0 -1.0   0.0  101   1.0  103.0   \n",
       "\n",
       "    A14    A15   A16    A17  A19   A20   A21   A22   A24 A25   A26   A27  \\\n",
       "0  17.5  103.0  18.5  104.0  300  21.5  50.0   9.0  22.0  75  22.5  70.0   \n",
       "1  18.0  104.0  19.0  105.0  200  20.0  50.0   9.0  20.0  80  21.0  73.0   \n",
       "2  18.0  104.0  19.0  105.0  200  19.5  50.0   9.0  20.0  79  21.0  73.0   \n",
       "3   5.0  103.0   6.0  104.0  200   7.0  50.0  10.0   7.5  70   8.0  78.0   \n",
       "4   2.0  104.0   3.0  105.0  200   4.0  50.0   9.0   4.0  80   5.0  73.0   \n",
       "\n",
       "    A28     B1   B2    B4    B5  B6    B7    B8    B9   B10   B11     B12  \\\n",
       "0   7.0  350.0  3.5   8.0   8.0  65  11.5  45.0  13.0  15.5  -1.0   800.0   \n",
       "1  22.0  320.0  3.5  23.0  23.0  80   6.0  45.0   7.5   9.0  10.0  1200.0   \n",
       "2  22.0  320.0  3.5  23.0  23.0  80   1.0  45.0   2.5   4.0   5.0  1200.0   \n",
       "3  14.5  290.0  3.5  15.5  15.5  65  18.0  45.0  20.5  23.0  -1.0   800.0   \n",
       "4   6.0  320.0  3.5   7.0   7.0  80   9.0  45.0  10.5  12.0  13.0  1200.0   \n",
       "\n",
       "   B14  A20_diff  A28_diff  B4_diff  B9_diff  B10_diff  B11_diff  A7-A5  \\\n",
       "0  400       0.5       0.5      1.0      1.5       1.5      -1.0    9.5   \n",
       "1  400       1.0       1.0      1.0      1.5       1.5       1.0    9.0   \n",
       "2  400       0.5       1.0      1.0      1.5       1.5       1.0    9.0   \n",
       "3  400       0.5       1.0      1.0      1.5       1.5      -1.0   21.5   \n",
       "4  420       1.0       1.0      1.0      1.5       1.5       1.0    1.0   \n",
       "\n",
       "   A9-A7  A11-A9  A14-A11  A16-A14  A20-A16  A24-A20  A26-A24  A28-A26  \\\n",
       "0   16.5     1.0      1.0      1.0      3.0      0.0      0.5      8.5   \n",
       "1   17.0     1.0      1.0      1.0      1.0     23.0      1.0      1.0   \n",
       "2   17.0     1.0      1.0      1.0      0.5      0.0      1.0      1.0   \n",
       "3    4.0     1.0      1.0      1.0      1.0      0.0      0.5      6.5   \n",
       "4    1.0     1.0      1.0      1.0      1.0     23.0      1.0      1.0   \n",
       "\n",
       "   B4-A28  B5-B4  B7-B5  B9-B7  B10-B9  \n",
       "0     0.5   23.0    3.5    1.5     1.0  \n",
       "1     0.0   23.0    7.0    1.5     0.0  \n",
       "2     0.0   23.0    2.0    1.5     0.0  \n",
       "3     0.0   23.0    2.5    2.5     1.0  \n",
       "4     0.0   23.0    2.0    1.5     0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['A1', 'A2', 'A3', 'A4', 'A6', 'A8', 'A10', 'A12', 'A13', 'A15', 'A17', 'A18', 'A19', 'A21', 'A22', 'A23', 'A25', 'A27', 'B1', 'B2', 'B3', 'B6', 'B8', 'B12', 'B13', 'B14']\n",
    "\n",
    "for col in num_cols:\n",
    "    if col in data.columns:\n",
    "        numerical_columns.append(col)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['b14/a1_a3_a4_a19_b1_b12'] = data['B14']/(data['A1']+data['A3']+data['A4']+data['A19']+data['B1']+data['B12'])\n",
    "\n",
    "numerical_columns.append('b14/a1_a3_a4_a19_b1_b12')\n",
    "\n",
    "# del data['A1']\n",
    "# del data['A3']\n",
    "# del data['A4']\n",
    "# categorical_columns.remove('A1')\n",
    "# categorical_columns.remove('A3')\n",
    "# categorical_columns.remove('A4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1390, 59)\n",
      "(150, 59)\n"
     ]
    }
   ],
   "source": [
    "for f in categorical_columns:\n",
    "    data[f] = data[f].map(dict(zip(data[f].unique(), range(0, data[f].nunique()))))\n",
    "train = data[:train.shape[0]]\n",
    "test  = data[train.shape[0]:]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1390, 219)\n",
      "(150, 219)\n"
     ]
    }
   ],
   "source": [
    "train['target'] = target\n",
    "train['intTarget'] = pd.cut(train['target'], 5, labels=False)\n",
    "train = pd.get_dummies(train, columns=['intTarget'])\n",
    "li = ['intTarget_0.0','intTarget_1.0','intTarget_2.0','intTarget_3.0','intTarget_4.0']\n",
    "mean_columns = []\n",
    "for f1 in categorical_columns:\n",
    "    cate_rate = train[f1].value_counts(normalize=True, dropna=False).values[0]\n",
    "    if cate_rate < 0.90:\n",
    "        for f2 in li:\n",
    "            col_name = 'B14_to_'+f1+\"_\"+f2+'_mean'\n",
    "            mean_columns.append(col_name)\n",
    "            order_label = train.groupby([f1])[f2].mean()\n",
    "            train[col_name] = train['B14'].map(order_label)\n",
    "            miss_rate = train[col_name].isnull().sum() * 100 / train[col_name].shape[0]\n",
    "            if miss_rate > 0:\n",
    "                train = train.drop([col_name], axis=1)\n",
    "                mean_columns.remove(col_name)\n",
    "            else:\n",
    "                test[col_name] = test['B14'].map(order_label)\n",
    "                \n",
    "                \n",
    "                \n",
    "#             col_name = f1+\"_\"+f2+'_mean'\n",
    "#             mean_columns.append(col_name)\n",
    "#             order_label = train.groupby([f1])[f2].mean()\n",
    "#             train[col_name] = train[f1].map(order_label)\n",
    "#             miss_rate = train[col_name].isnull().sum() * 100 / train[col_name].shape[0]\n",
    "#             if miss_rate > 0:\n",
    "#                 train = train.drop([col_name], axis=1)\n",
    "#                 mean_columns.remove(col_name)\n",
    "#             else:\n",
    "#                 test[col_name] = test[f1].map(order_label)\n",
    "            \n",
    "                        \n",
    "train.drop(li+['target'], axis=1, inplace=True)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ = pd.DataFrame(train, columns=best_features)\n",
    "# test_ = pd.DataFrame(test, columns=best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train_.values\n",
    "# X_test = test_.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[mean_columns+numerical_columns].values\n",
    "X_test = test[mean_columns+numerical_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1390, 2444)\n",
      "(150, 2444)\n"
     ]
    }
   ],
   "source": [
    "# one hot\n",
    "enc = OneHotEncoder()\n",
    "for f in categorical_columns:\n",
    "    enc.fit(data[f].values.reshape(-1, 1))\n",
    "    X_train = sparse.hstack((X_train, enc.transform(train[f].values.reshape(-1, 1))), 'csr')\n",
    "    X_test = sparse.hstack((X_test, enc.transform(test[f].values.reshape(-1, 1))), 'csr')\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_params = {'learning_rate': 0.1,\n",
    "#               'depth': 12,\n",
    "#               'l2_leaf_reg': 10,\n",
    "#               'bootstrap_type': 'Bernoulli',\n",
    "#               'od_type': 'Iter',\n",
    "#               'od_wait': 50,\n",
    "#               'random_seed': 11,\n",
    "#               'allow_writing_files': False}\n",
    "# folds = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "# oof_cat = np.zeros(len(train))\n",
    "# predictions_cat = np.zeros(len(test))\n",
    "# for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "#     print(f\"fold {fold_+1}\")\n",
    "#     (trn_data_X, trn_data_y, val_data_X, val_data_y) = (\n",
    "#         X_train.toarray()[trn_idx],\n",
    "#         y_train[trn_idx],\n",
    "#         X_train.toarray()[val_idx],\n",
    "#         y_train[val_idx])\n",
    "#     clf = CatBoostRegressor(iterations=20000, eval_metric='RMSE', use_best_model=True, **cat_params)\n",
    "#     clf.fit(trn_data_X, trn_data_y,\n",
    "#             eval_set=(val_data_X, val_data_y),\n",
    "#             logging_level='Verbose')\n",
    "#     oof_cat[val_idx] = clf.predict(val_data_X)\n",
    "    \n",
    "#     predictions_cat += clf.predict(X_test.toarray()) / folds.n_splits\n",
    "    \n",
    "# print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_cat, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000227199\tvalid_1's l2: 0.000243936\n",
      "[400]\ttraining's l2: 0.00011462\tvalid_1's l2: 0.000166589\n",
      "[600]\ttraining's l2: 8.1562e-05\tvalid_1's l2: 0.000151515\n",
      "[800]\ttraining's l2: 6.43996e-05\tvalid_1's l2: 0.000147521\n",
      "[1000]\ttraining's l2: 5.36803e-05\tvalid_1's l2: 0.000146931\n",
      "[1200]\ttraining's l2: 4.62071e-05\tvalid_1's l2: 0.000146595\n",
      "Early stopping, best iteration is:\n",
      "[1222]\ttraining's l2: 4.55322e-05\tvalid_1's l2: 0.000146559\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000224355\tvalid_1's l2: 0.000256856\n",
      "[400]\ttraining's l2: 0.000114961\tvalid_1's l2: 0.000155475\n",
      "[600]\ttraining's l2: 8.34697e-05\tvalid_1's l2: 0.000133645\n",
      "[800]\ttraining's l2: 6.77587e-05\tvalid_1's l2: 0.000125036\n",
      "[1000]\ttraining's l2: 5.7173e-05\tvalid_1's l2: 0.00012123\n",
      "[1200]\ttraining's l2: 4.98857e-05\tvalid_1's l2: 0.000119871\n",
      "[1400]\ttraining's l2: 4.43804e-05\tvalid_1's l2: 0.000119125\n",
      "[1600]\ttraining's l2: 3.99467e-05\tvalid_1's l2: 0.000118643\n",
      "Early stopping, best iteration is:\n",
      "[1680]\ttraining's l2: 3.84124e-05\tvalid_1's l2: 0.000118497\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000226618\tvalid_1's l2: 0.000247509\n",
      "[400]\ttraining's l2: 0.000117011\tvalid_1's l2: 0.000149506\n",
      "[600]\ttraining's l2: 8.38172e-05\tvalid_1's l2: 0.000128513\n",
      "[800]\ttraining's l2: 6.68947e-05\tvalid_1's l2: 0.000122534\n",
      "[1000]\ttraining's l2: 5.61923e-05\tvalid_1's l2: 0.000120047\n",
      "[1200]\ttraining's l2: 4.87101e-05\tvalid_1's l2: 0.000118669\n",
      "[1400]\ttraining's l2: 4.30358e-05\tvalid_1's l2: 0.000118487\n",
      "Early stopping, best iteration is:\n",
      "[1460]\ttraining's l2: 4.16203e-05\tvalid_1's l2: 0.000118326\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000221125\tvalid_1's l2: 0.000270246\n",
      "[400]\ttraining's l2: 0.000116805\tvalid_1's l2: 0.000171722\n",
      "[600]\ttraining's l2: 8.55131e-05\tvalid_1's l2: 0.000147332\n",
      "[800]\ttraining's l2: 6.80809e-05\tvalid_1's l2: 0.000135791\n",
      "[1000]\ttraining's l2: 5.712e-05\tvalid_1's l2: 0.00013188\n",
      "[1200]\ttraining's l2: 4.94916e-05\tvalid_1's l2: 0.000130523\n",
      "[1400]\ttraining's l2: 4.36553e-05\tvalid_1's l2: 0.000129584\n",
      "[1600]\ttraining's l2: 3.92302e-05\tvalid_1's l2: 0.000128862\n",
      "Early stopping, best iteration is:\n",
      "[1626]\ttraining's l2: 3.87434e-05\tvalid_1's l2: 0.000128733\n",
      "fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000223237\tvalid_1's l2: 0.000271091\n",
      "[400]\ttraining's l2: 0.000114609\tvalid_1's l2: 0.00018305\n",
      "[600]\ttraining's l2: 8.33172e-05\tvalid_1's l2: 0.000167218\n",
      "[800]\ttraining's l2: 6.67681e-05\tvalid_1's l2: 0.000158349\n",
      "[1000]\ttraining's l2: 5.63788e-05\tvalid_1's l2: 0.000154897\n",
      "[1200]\ttraining's l2: 4.93085e-05\tvalid_1's l2: 0.000153691\n",
      "[1400]\ttraining's l2: 4.38881e-05\tvalid_1's l2: 0.0001529\n",
      "[1600]\ttraining's l2: 3.96209e-05\tvalid_1's l2: 0.000152783\n",
      "[1800]\ttraining's l2: 3.60925e-05\tvalid_1's l2: 0.000152199\n",
      "Early stopping, best iteration is:\n",
      "[1804]\ttraining's l2: 3.60289e-05\tvalid_1's l2: 0.000152175\n",
      "CV score: 0.00013286\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 120,\n",
    "         'min_data_in_leaf': 12, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8,\n",
    "         \"bagging_seed\": 6,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.01,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "feature_importance = np.zeros(X_train.shape[1])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(f\"fold {fold_+1}\")\n",
    "    trn_data = lgb.Dataset(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train[val_idx], num_iteration=clf.best_iteration)    \n",
    "    predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    feature_importance += clf.feature_importance() / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.73641571194763"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_features = []\n",
    "for i, imp in enumerate(feature_importance):\n",
    "    if imp > 30:\n",
    "        good_features.append(i)\n",
    "X_train = X_train[:, good_features]\n",
    "X_test = X_test[:, good_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.000389059\tvalid_1's l2: 0.000361796\n",
      "[400]\ttraining's l2: 0.000227889\tvalid_1's l2: 0.000238018\n",
      "[600]\ttraining's l2: 0.000164657\tvalid_1's l2: 0.00019131\n",
      "[800]\ttraining's l2: 0.000135854\tvalid_1's l2: 0.000171933\n",
      "[1000]\ttraining's l2: 0.000116981\tvalid_1's l2: 0.000160923\n",
      "[1200]\ttraining's l2: 0.000103647\tvalid_1's l2: 0.000154169\n",
      "[1400]\ttraining's l2: 9.42069e-05\tvalid_1's l2: 0.000149725\n",
      "[1600]\ttraining's l2: 8.72658e-05\tvalid_1's l2: 0.000146528\n",
      "[1800]\ttraining's l2: 8.20169e-05\tvalid_1's l2: 0.000144659\n",
      "[2000]\ttraining's l2: 7.79439e-05\tvalid_1's l2: 0.000143332\n",
      "[2200]\ttraining's l2: 7.47274e-05\tvalid_1's l2: 0.000142486\n",
      "[2400]\ttraining's l2: 7.18296e-05\tvalid_1's l2: 0.000141829\n",
      "[2600]\ttraining's l2: 6.93141e-05\tvalid_1's l2: 0.000141407\n",
      "[2800]\ttraining's l2: 6.71248e-05\tvalid_1's l2: 0.000141097\n",
      "[3000]\ttraining's l2: 6.52139e-05\tvalid_1's l2: 0.000140954\n",
      "[3200]\ttraining's l2: 6.34399e-05\tvalid_1's l2: 0.000140789\n",
      "[3400]\ttraining's l2: 6.18586e-05\tvalid_1's l2: 0.000140682\n",
      "[3600]\ttraining's l2: 6.04255e-05\tvalid_1's l2: 0.000140579\n",
      "[3800]\ttraining's l2: 5.90846e-05\tvalid_1's l2: 0.000140539\n",
      "[4000]\ttraining's l2: 5.78377e-05\tvalid_1's l2: 0.000140501\n",
      "[4200]\ttraining's l2: 5.67003e-05\tvalid_1's l2: 0.000140394\n",
      "[4400]\ttraining's l2: 5.56812e-05\tvalid_1's l2: 0.000140384\n",
      "Early stopping, best iteration is:\n",
      "[4329]\ttraining's l2: 5.60101e-05\tvalid_1's l2: 0.000140306\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.000382331\tvalid_1's l2: 0.000412703\n",
      "[400]\ttraining's l2: 0.00022792\tvalid_1's l2: 0.000252854\n",
      "[600]\ttraining's l2: 0.000167213\tvalid_1's l2: 0.00019255\n",
      "[800]\ttraining's l2: 0.000139296\tvalid_1's l2: 0.000167853\n",
      "[1000]\ttraining's l2: 0.000119872\tvalid_1's l2: 0.000151918\n",
      "[1200]\ttraining's l2: 0.000106653\tvalid_1's l2: 0.000141662\n",
      "[1400]\ttraining's l2: 9.72543e-05\tvalid_1's l2: 0.00013456\n",
      "[1600]\ttraining's l2: 9.06371e-05\tvalid_1's l2: 0.000130204\n",
      "[1800]\ttraining's l2: 8.54546e-05\tvalid_1's l2: 0.000127001\n",
      "[2000]\ttraining's l2: 8.14006e-05\tvalid_1's l2: 0.000124758\n",
      "[2200]\ttraining's l2: 7.82198e-05\tvalid_1's l2: 0.000123114\n",
      "[2400]\ttraining's l2: 7.54314e-05\tvalid_1's l2: 0.000122\n",
      "[2600]\ttraining's l2: 7.29481e-05\tvalid_1's l2: 0.000121008\n",
      "[2800]\ttraining's l2: 7.07344e-05\tvalid_1's l2: 0.000120282\n",
      "[3000]\ttraining's l2: 6.89061e-05\tvalid_1's l2: 0.000119762\n",
      "[3200]\ttraining's l2: 6.72308e-05\tvalid_1's l2: 0.000119192\n",
      "[3400]\ttraining's l2: 6.56699e-05\tvalid_1's l2: 0.000118607\n",
      "[3600]\ttraining's l2: 6.42599e-05\tvalid_1's l2: 0.000118388\n",
      "[3800]\ttraining's l2: 6.29684e-05\tvalid_1's l2: 0.000117938\n",
      "[4000]\ttraining's l2: 6.18474e-05\tvalid_1's l2: 0.000117692\n",
      "[4200]\ttraining's l2: 6.07126e-05\tvalid_1's l2: 0.000117416\n",
      "[4400]\ttraining's l2: 5.97235e-05\tvalid_1's l2: 0.000117169\n",
      "[4600]\ttraining's l2: 5.87642e-05\tvalid_1's l2: 0.000117081\n",
      "[4800]\ttraining's l2: 5.78491e-05\tvalid_1's l2: 0.000116869\n",
      "[5000]\ttraining's l2: 5.69708e-05\tvalid_1's l2: 0.000116808\n",
      "[5200]\ttraining's l2: 5.61602e-05\tvalid_1's l2: 0.000116747\n",
      "[5400]\ttraining's l2: 5.54153e-05\tvalid_1's l2: 0.000116639\n",
      "[5600]\ttraining's l2: 5.46888e-05\tvalid_1's l2: 0.000116535\n",
      "[5800]\ttraining's l2: 5.40084e-05\tvalid_1's l2: 0.000116458\n",
      "[6000]\ttraining's l2: 5.33344e-05\tvalid_1's l2: 0.000116391\n",
      "[6200]\ttraining's l2: 5.27195e-05\tvalid_1's l2: 0.000116346\n",
      "[6400]\ttraining's l2: 5.21154e-05\tvalid_1's l2: 0.000116402\n",
      "Early stopping, best iteration is:\n",
      "[6247]\ttraining's l2: 5.25867e-05\tvalid_1's l2: 0.000116334\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.000380627\tvalid_1's l2: 0.000396421\n",
      "[400]\ttraining's l2: 0.000225889\tvalid_1's l2: 0.000242202\n",
      "[600]\ttraining's l2: 0.000166224\tvalid_1's l2: 0.00018419\n",
      "[800]\ttraining's l2: 0.000137496\tvalid_1's l2: 0.000159003\n",
      "[1000]\ttraining's l2: 0.000118375\tvalid_1's l2: 0.000144808\n",
      "[1200]\ttraining's l2: 0.00010505\tvalid_1's l2: 0.000136269\n",
      "[1400]\ttraining's l2: 9.55642e-05\tvalid_1's l2: 0.000130746\n",
      "[1600]\ttraining's l2: 8.89265e-05\tvalid_1's l2: 0.000127519\n",
      "[1800]\ttraining's l2: 8.37146e-05\tvalid_1's l2: 0.00012542\n",
      "[2000]\ttraining's l2: 7.96004e-05\tvalid_1's l2: 0.000124082\n",
      "[2200]\ttraining's l2: 7.63438e-05\tvalid_1's l2: 0.000123175\n",
      "[2400]\ttraining's l2: 7.34736e-05\tvalid_1's l2: 0.00012247\n",
      "[2600]\ttraining's l2: 7.10351e-05\tvalid_1's l2: 0.000121959\n",
      "[2800]\ttraining's l2: 6.89015e-05\tvalid_1's l2: 0.000121638\n",
      "[3000]\ttraining's l2: 6.6997e-05\tvalid_1's l2: 0.000121346\n",
      "[3200]\ttraining's l2: 6.52975e-05\tvalid_1's l2: 0.000121031\n",
      "[3400]\ttraining's l2: 6.37205e-05\tvalid_1's l2: 0.000120763\n",
      "[3600]\ttraining's l2: 6.23426e-05\tvalid_1's l2: 0.000120622\n",
      "[3800]\ttraining's l2: 6.09919e-05\tvalid_1's l2: 0.000120678\n",
      "Early stopping, best iteration is:\n",
      "[3690]\ttraining's l2: 6.17243e-05\tvalid_1's l2: 0.000120605\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.000372357\tvalid_1's l2: 0.000417938\n",
      "[400]\ttraining's l2: 0.000221469\tvalid_1's l2: 0.000262851\n",
      "[600]\ttraining's l2: 0.000162195\tvalid_1's l2: 0.000204627\n",
      "[800]\ttraining's l2: 0.000135543\tvalid_1's l2: 0.000180446\n",
      "[1000]\ttraining's l2: 0.000118357\tvalid_1's l2: 0.000164391\n",
      "[1200]\ttraining's l2: 0.000105833\tvalid_1's l2: 0.000152901\n",
      "[1400]\ttraining's l2: 9.68401e-05\tvalid_1's l2: 0.000145712\n",
      "[1600]\ttraining's l2: 9.00759e-05\tvalid_1's l2: 0.000140647\n",
      "[1800]\ttraining's l2: 8.49135e-05\tvalid_1's l2: 0.000137488\n",
      "[2000]\ttraining's l2: 8.0881e-05\tvalid_1's l2: 0.00013527\n",
      "[2200]\ttraining's l2: 7.76469e-05\tvalid_1's l2: 0.00013386\n",
      "[2400]\ttraining's l2: 7.47933e-05\tvalid_1's l2: 0.000132753\n",
      "[2600]\ttraining's l2: 7.2296e-05\tvalid_1's l2: 0.000131864\n",
      "[2800]\ttraining's l2: 7.01356e-05\tvalid_1's l2: 0.000130997\n",
      "[3000]\ttraining's l2: 6.82234e-05\tvalid_1's l2: 0.000130398\n",
      "[3200]\ttraining's l2: 6.65184e-05\tvalid_1's l2: 0.000129879\n",
      "[3400]\ttraining's l2: 6.49038e-05\tvalid_1's l2: 0.000129354\n",
      "[3600]\ttraining's l2: 6.35172e-05\tvalid_1's l2: 0.000128989\n",
      "[3800]\ttraining's l2: 6.21809e-05\tvalid_1's l2: 0.000128619\n",
      "[4000]\ttraining's l2: 6.097e-05\tvalid_1's l2: 0.000128226\n",
      "[4200]\ttraining's l2: 5.98298e-05\tvalid_1's l2: 0.000127937\n",
      "[4400]\ttraining's l2: 5.88376e-05\tvalid_1's l2: 0.000127664\n",
      "[4600]\ttraining's l2: 5.78188e-05\tvalid_1's l2: 0.000127323\n",
      "[4800]\ttraining's l2: 5.68826e-05\tvalid_1's l2: 0.000127042\n",
      "[5000]\ttraining's l2: 5.60124e-05\tvalid_1's l2: 0.000126881\n",
      "[5200]\ttraining's l2: 5.51952e-05\tvalid_1's l2: 0.0001268\n",
      "[5400]\ttraining's l2: 5.44488e-05\tvalid_1's l2: 0.000126701\n",
      "[5600]\ttraining's l2: 5.37214e-05\tvalid_1's l2: 0.000126572\n",
      "[5800]\ttraining's l2: 5.30338e-05\tvalid_1's l2: 0.000126405\n",
      "[6000]\ttraining's l2: 5.23785e-05\tvalid_1's l2: 0.000126345\n",
      "[6200]\ttraining's l2: 5.17392e-05\tvalid_1's l2: 0.000126235\n",
      "[6400]\ttraining's l2: 5.11533e-05\tvalid_1's l2: 0.000126158\n",
      "[6600]\ttraining's l2: 5.0584e-05\tvalid_1's l2: 0.000126155\n",
      "[6800]\ttraining's l2: 5.00531e-05\tvalid_1's l2: 0.000126026\n",
      "[7000]\ttraining's l2: 4.95164e-05\tvalid_1's l2: 0.00012593\n",
      "[7200]\ttraining's l2: 4.89985e-05\tvalid_1's l2: 0.000125879\n",
      "[7400]\ttraining's l2: 4.85071e-05\tvalid_1's l2: 0.000125786\n",
      "[7600]\ttraining's l2: 4.80585e-05\tvalid_1's l2: 0.000125753\n",
      "[7800]\ttraining's l2: 4.76178e-05\tvalid_1's l2: 0.000125698\n",
      "[8000]\ttraining's l2: 4.72072e-05\tvalid_1's l2: 0.000125655\n",
      "[8200]\ttraining's l2: 4.67936e-05\tvalid_1's l2: 0.000125554\n",
      "[8400]\ttraining's l2: 4.64096e-05\tvalid_1's l2: 0.000125509\n",
      "[8600]\ttraining's l2: 4.60096e-05\tvalid_1's l2: 0.000125466\n",
      "[8800]\ttraining's l2: 4.56361e-05\tvalid_1's l2: 0.000125378\n",
      "[9000]\ttraining's l2: 4.5298e-05\tvalid_1's l2: 0.000125327\n",
      "[9200]\ttraining's l2: 4.49332e-05\tvalid_1's l2: 0.000125317\n",
      "[9400]\ttraining's l2: 4.45942e-05\tvalid_1's l2: 0.000125333\n",
      "Early stopping, best iteration is:\n",
      "[9287]\ttraining's l2: 4.47829e-05\tvalid_1's l2: 0.000125275\n",
      "fold 5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l2: 0.00037771\tvalid_1's l2: 0.000401425\n",
      "[400]\ttraining's l2: 0.000222019\tvalid_1's l2: 0.000259586\n",
      "[600]\ttraining's l2: 0.000161551\tvalid_1's l2: 0.000207821\n",
      "[800]\ttraining's l2: 0.000133536\tvalid_1's l2: 0.000187662\n",
      "[1000]\ttraining's l2: 0.000116113\tvalid_1's l2: 0.000175534\n",
      "[1200]\ttraining's l2: 0.000103512\tvalid_1's l2: 0.00016673\n",
      "[1400]\ttraining's l2: 9.45698e-05\tvalid_1's l2: 0.000161308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1600]\ttraining's l2: 8.82801e-05\tvalid_1's l2: 0.000157543\n",
      "[1800]\ttraining's l2: 8.36151e-05\tvalid_1's l2: 0.00015501\n",
      "[2000]\ttraining's l2: 7.9821e-05\tvalid_1's l2: 0.000153001\n",
      "[2200]\ttraining's l2: 7.66624e-05\tvalid_1's l2: 0.000151252\n",
      "[2400]\ttraining's l2: 7.40481e-05\tvalid_1's l2: 0.000150044\n",
      "[2600]\ttraining's l2: 7.18322e-05\tvalid_1's l2: 0.000148818\n",
      "[2800]\ttraining's l2: 6.984e-05\tvalid_1's l2: 0.000147989\n",
      "[3000]\ttraining's l2: 6.80104e-05\tvalid_1's l2: 0.000147408\n",
      "[3200]\ttraining's l2: 6.63706e-05\tvalid_1's l2: 0.000146763\n",
      "[3400]\ttraining's l2: 6.48648e-05\tvalid_1's l2: 0.000146223\n",
      "[3600]\ttraining's l2: 6.35131e-05\tvalid_1's l2: 0.000145736\n",
      "[3800]\ttraining's l2: 6.22624e-05\tvalid_1's l2: 0.000145147\n",
      "[4000]\ttraining's l2: 6.11032e-05\tvalid_1's l2: 0.000144697\n",
      "[4200]\ttraining's l2: 6.0038e-05\tvalid_1's l2: 0.000144411\n",
      "[4400]\ttraining's l2: 5.90301e-05\tvalid_1's l2: 0.000144185\n",
      "[4600]\ttraining's l2: 5.80957e-05\tvalid_1's l2: 0.000143992\n",
      "[4800]\ttraining's l2: 5.72132e-05\tvalid_1's l2: 0.000143876\n",
      "[5000]\ttraining's l2: 5.6389e-05\tvalid_1's l2: 0.000143665\n",
      "[5200]\ttraining's l2: 5.5622e-05\tvalid_1's l2: 0.00014346\n",
      "[5400]\ttraining's l2: 5.48861e-05\tvalid_1's l2: 0.000143368\n",
      "[5600]\ttraining's l2: 5.41831e-05\tvalid_1's l2: 0.000143302\n",
      "[5800]\ttraining's l2: 5.35199e-05\tvalid_1's l2: 0.00014317\n",
      "[6000]\ttraining's l2: 5.28867e-05\tvalid_1's l2: 0.000142892\n",
      "[6200]\ttraining's l2: 5.22453e-05\tvalid_1's l2: 0.000142847\n",
      "[6400]\ttraining's l2: 5.16609e-05\tvalid_1's l2: 0.000142751\n",
      "[6600]\ttraining's l2: 5.11398e-05\tvalid_1's l2: 0.000142729\n",
      "[6800]\ttraining's l2: 5.0645e-05\tvalid_1's l2: 0.000142731\n",
      "[7000]\ttraining's l2: 5.01277e-05\tvalid_1's l2: 0.000142663\n",
      "Early stopping, best iteration is:\n",
      "[6993]\ttraining's l2: 5.01434e-05\tvalid_1's l2: 0.000142643\n",
      "CV score: 0.00012903\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 120,\n",
    "         'min_data_in_leaf': 15, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.003,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8,\n",
    "         \"bagging_seed\": 6,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.05,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(f\"fold {fold_+1}\")\n",
    "    trn_data = lgb.Dataset(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 200)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:0.422529\tvalid_data-rmse:0.42369\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256766\tvalid_data-rmse:0.257975\n",
      "[200]\ttrain-rmse:0.156495\tvalid_data-rmse:0.157566\n",
      "[300]\ttrain-rmse:0.095866\tvalid_data-rmse:0.097085\n",
      "[400]\ttrain-rmse:0.0593\tvalid_data-rmse:0.060766\n",
      "[500]\ttrain-rmse:0.0373\tvalid_data-rmse:0.039019\n",
      "[600]\ttrain-rmse:0.024096\tvalid_data-rmse:0.026275\n",
      "[700]\ttrain-rmse:0.016155\tvalid_data-rmse:0.019028\n",
      "[800]\ttrain-rmse:0.011387\tvalid_data-rmse:0.015174\n",
      "[900]\ttrain-rmse:0.008493\tvalid_data-rmse:0.013241\n",
      "[1000]\ttrain-rmse:0.006689\tvalid_data-rmse:0.012338\n",
      "[1100]\ttrain-rmse:0.005496\tvalid_data-rmse:0.011944\n",
      "[1200]\ttrain-rmse:0.0047\tvalid_data-rmse:0.011802\n",
      "[1300]\ttrain-rmse:0.004116\tvalid_data-rmse:0.011766\n",
      "[1400]\ttrain-rmse:0.003665\tvalid_data-rmse:0.01178\n",
      "[1500]\ttrain-rmse:0.003269\tvalid_data-rmse:0.011823\n",
      "Stopping. Best iteration:\n",
      "[1318]\ttrain-rmse:0.00403\tvalid_data-rmse:0.011758\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:0.422709\tvalid_data-rmse:0.42299\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256898\tvalid_data-rmse:0.256815\n",
      "[200]\ttrain-rmse:0.156563\tvalid_data-rmse:0.156204\n",
      "[300]\ttrain-rmse:0.095904\tvalid_data-rmse:0.095288\n",
      "[400]\ttrain-rmse:0.059343\tvalid_data-rmse:0.05865\n",
      "[500]\ttrain-rmse:0.037349\tvalid_data-rmse:0.036905\n",
      "[600]\ttrain-rmse:0.024148\tvalid_data-rmse:0.024351\n",
      "[700]\ttrain-rmse:0.016209\tvalid_data-rmse:0.017419\n",
      "[800]\ttrain-rmse:0.011426\tvalid_data-rmse:0.013863\n",
      "[900]\ttrain-rmse:0.008503\tvalid_data-rmse:0.012179\n",
      "[1000]\ttrain-rmse:0.006687\tvalid_data-rmse:0.011428\n",
      "[1100]\ttrain-rmse:0.005511\tvalid_data-rmse:0.01109\n",
      "[1200]\ttrain-rmse:0.004745\tvalid_data-rmse:0.010946\n",
      "[1300]\ttrain-rmse:0.004176\tvalid_data-rmse:0.01089\n",
      "[1400]\ttrain-rmse:0.003733\tvalid_data-rmse:0.01086\n",
      "[1500]\ttrain-rmse:0.003357\tvalid_data-rmse:0.010847\n",
      "[1600]\ttrain-rmse:0.003031\tvalid_data-rmse:0.010834\n",
      "[1700]\ttrain-rmse:0.002748\tvalid_data-rmse:0.010831\n",
      "[1800]\ttrain-rmse:0.002502\tvalid_data-rmse:0.010842\n",
      "Stopping. Best iteration:\n",
      "[1666]\ttrain-rmse:0.002835\tvalid_data-rmse:0.010828\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:0.422401\tvalid_data-rmse:0.424221\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256703\tvalid_data-rmse:0.258329\n",
      "[200]\ttrain-rmse:0.156466\tvalid_data-rmse:0.15773\n",
      "[300]\ttrain-rmse:0.095856\tvalid_data-rmse:0.096854\n",
      "[400]\ttrain-rmse:0.059287\tvalid_data-rmse:0.06013\n",
      "[500]\ttrain-rmse:0.037265\tvalid_data-rmse:0.038104\n",
      "[600]\ttrain-rmse:0.02408\tvalid_data-rmse:0.025237\n",
      "[700]\ttrain-rmse:0.01614\tvalid_data-rmse:0.017914\n",
      "[800]\ttrain-rmse:0.011327\tvalid_data-rmse:0.014025\n",
      "[900]\ttrain-rmse:0.008387\tvalid_data-rmse:0.012104\n",
      "[1000]\ttrain-rmse:0.006577\tvalid_data-rmse:0.011241\n",
      "[1100]\ttrain-rmse:0.005419\tvalid_data-rmse:0.010891\n",
      "[1200]\ttrain-rmse:0.004633\tvalid_data-rmse:0.010761\n",
      "[1300]\ttrain-rmse:0.004059\tvalid_data-rmse:0.010736\n",
      "[1400]\ttrain-rmse:0.003612\tvalid_data-rmse:0.01074\n",
      "Stopping. Best iteration:\n",
      "[1287]\ttrain-rmse:0.00413\tvalid_data-rmse:0.010735\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:0.422889\tvalid_data-rmse:0.422266\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256993\tvalid_data-rmse:0.256666\n",
      "[200]\ttrain-rmse:0.156621\tvalid_data-rmse:0.156389\n",
      "[300]\ttrain-rmse:0.095907\tvalid_data-rmse:0.095499\n",
      "[400]\ttrain-rmse:0.059302\tvalid_data-rmse:0.058891\n",
      "[500]\ttrain-rmse:0.037298\tvalid_data-rmse:0.037027\n",
      "[600]\ttrain-rmse:0.024097\tvalid_data-rmse:0.024283\n",
      "[700]\ttrain-rmse:0.016182\tvalid_data-rmse:0.017197\n",
      "[800]\ttrain-rmse:0.011419\tvalid_data-rmse:0.013568\n",
      "[900]\ttrain-rmse:0.008505\tvalid_data-rmse:0.011902\n",
      "[1000]\ttrain-rmse:0.00668\tvalid_data-rmse:0.011216\n",
      "[1100]\ttrain-rmse:0.005494\tvalid_data-rmse:0.010931\n",
      "[1200]\ttrain-rmse:0.004677\tvalid_data-rmse:0.01084\n",
      "[1300]\ttrain-rmse:0.004097\tvalid_data-rmse:0.010827\n",
      "[1400]\ttrain-rmse:0.003656\tvalid_data-rmse:0.010836\n",
      "[1500]\ttrain-rmse:0.003278\tvalid_data-rmse:0.010849\n",
      "Stopping. Best iteration:\n",
      "[1324]\ttrain-rmse:0.003979\tvalid_data-rmse:0.010822\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:0.423288\tvalid_data-rmse:0.420638\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.257217\tvalid_data-rmse:0.254667\n",
      "[200]\ttrain-rmse:0.156731\tvalid_data-rmse:0.154846\n",
      "[300]\ttrain-rmse:0.096015\tvalid_data-rmse:0.094759\n",
      "[400]\ttrain-rmse:0.059395\tvalid_data-rmse:0.058603\n",
      "[500]\ttrain-rmse:0.037338\tvalid_data-rmse:0.037048\n",
      "[600]\ttrain-rmse:0.024104\tvalid_data-rmse:0.024614\n",
      "[700]\ttrain-rmse:0.016153\tvalid_data-rmse:0.017827\n",
      "[800]\ttrain-rmse:0.011371\tvalid_data-rmse:0.01443\n",
      "[900]\ttrain-rmse:0.008425\tvalid_data-rmse:0.012941\n",
      "[1000]\ttrain-rmse:0.006606\tvalid_data-rmse:0.012356\n",
      "[1100]\ttrain-rmse:0.005429\tvalid_data-rmse:0.01218\n",
      "[1200]\ttrain-rmse:0.004681\tvalid_data-rmse:0.012159\n",
      "[1300]\ttrain-rmse:0.004143\tvalid_data-rmse:0.012192\n",
      "Stopping. Best iteration:\n",
      "[1183]\ttrain-rmse:0.004786\tvalid_data-rmse:0.012153\n",
      "\n",
      "CV score: 0.00012711\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'eta': 0.005, 'max_depth': 12, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 4}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "oof_xgb = np.zeros(len(train))\n",
    "predictions_xgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=100, params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(X_train[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_h2o = pd.read_csv('oof_h2o.csv', header=None).values.reshape(-1)\n",
    "# predictions_h2o = pd.read_csv('predictions_h2o.csv', header=None).values.reshape(-1)\n",
    "# print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_h2o, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack = np.vstack([oof_lgb, oof_xgb]).transpose()\n",
    "test_stack = np.vstack([predictions_lgb, predictions_xgb]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985151</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  1.000000  0.985151\n",
       "1  0.985151  1.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_stack).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "[0.44186566 0.57170683]\n",
      "fold 1\n",
      "[0.38277962 0.61666664]\n",
      "fold 2\n",
      "[0.45654127 0.54837778]\n",
      "fold 3\n",
      "[0.50591204 0.49918328]\n",
      "fold 4\n",
      "[0.45185683 0.5581124 ]\n",
      "fold 5\n",
      "[0.50050107 0.51416893]\n",
      "fold 6\n",
      "[0.42206392 0.58194952]\n",
      "fold 7\n",
      "[0.51253751 0.49555955]\n",
      "fold 8\n",
      "[0.38429712 0.61819121]\n",
      "fold 9\n",
      "[0.42419191 0.57980485]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0001232886103972429"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=4590)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    clf_3 = BayesianRidge()\n",
    "    clf_3.fit(trn_data, trn_y)\n",
    "    print(clf_3.coef_)\n",
    "    \n",
    "    oof_stack[val_idx] = clf_3.predict(val_data)\n",
    "    predictions += clf_3.predict(test_stack) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('jinnan_round1_submit_20181227.csv', header=None)\n",
    "sub_df[1] = predictions\n",
    "sub_df[1] = sub_df[1].apply(lambda x:round(x, 3))\n",
    "sub_df.to_csv(\"submit.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4278535233333333"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sub_df[1]**2).sum()/len(sub_df.index)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_1656</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1548</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_769</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_1881</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_1807</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample_145</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sample_1212</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample_944</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample_829</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample_616</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sample_1690</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sample_114</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sample_185</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sample_1141</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sample_1460</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sample_1835</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sample_1539</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sample_598</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sample_1800</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sample_394</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sample_1146</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sample_149</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sample_1750</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sample_1977</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sample_1830</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sample_818</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sample_881</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sample_77</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sample_1240</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sample_309</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>sample_49</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>sample_474</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>sample_1716</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>sample_1169</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>sample_1925</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>sample_667</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>sample_176</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>sample_1908</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>sample_160</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>sample_35</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>sample_1403</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>sample_1806</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>sample_241</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>sample_1059</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>sample_746</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>sample_513</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>sample_1088</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>sample_1370</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>sample_523</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>sample_319</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>sample_1923</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>sample_1296</td>\n",
       "      <td>0.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>sample_1152</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>sample_982</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>sample_304</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>sample_502</td>\n",
       "      <td>0.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>sample_1951</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>sample_386</td>\n",
       "      <td>0.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>sample_362</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>sample_522</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1\n",
       "0    sample_1656  0.907\n",
       "1    sample_1548  0.879\n",
       "2     sample_769  0.933\n",
       "3    sample_1881  0.903\n",
       "4    sample_1807  0.927\n",
       "5     sample_145  0.927\n",
       "6    sample_1212  0.935\n",
       "7     sample_944  0.896\n",
       "8     sample_829  0.934\n",
       "9     sample_616  0.925\n",
       "10   sample_1690  0.947\n",
       "11    sample_114  0.947\n",
       "12    sample_185  0.929\n",
       "13   sample_1141  0.958\n",
       "14   sample_1460  0.892\n",
       "15   sample_1835  0.920\n",
       "16   sample_1539  0.892\n",
       "17    sample_598  0.935\n",
       "18   sample_1800  0.976\n",
       "19    sample_394  0.893\n",
       "20   sample_1146  0.909\n",
       "21    sample_149  0.976\n",
       "22   sample_1750  0.939\n",
       "23   sample_1977  0.933\n",
       "24   sample_1830  0.979\n",
       "25    sample_818  0.939\n",
       "26    sample_881  0.897\n",
       "27     sample_77  0.899\n",
       "28   sample_1240  0.975\n",
       "29    sample_309  0.890\n",
       "..           ...    ...\n",
       "120    sample_49  0.899\n",
       "121   sample_474  0.895\n",
       "122  sample_1716  0.897\n",
       "123  sample_1169  0.970\n",
       "124  sample_1925  0.934\n",
       "125   sample_667  0.928\n",
       "126   sample_176  0.928\n",
       "127  sample_1908  0.900\n",
       "128   sample_160  0.930\n",
       "129    sample_35  0.964\n",
       "130  sample_1403  0.925\n",
       "131  sample_1806  0.979\n",
       "132   sample_241  0.936\n",
       "133  sample_1059  0.941\n",
       "134   sample_746  0.947\n",
       "135   sample_513  0.934\n",
       "136  sample_1088  0.935\n",
       "137  sample_1370  0.932\n",
       "138   sample_523  0.939\n",
       "139   sample_319  0.894\n",
       "140  sample_1923  0.976\n",
       "141  sample_1296  0.942\n",
       "142  sample_1152  0.907\n",
       "143   sample_982  0.893\n",
       "144   sample_304  0.894\n",
       "145   sample_502  0.966\n",
       "146  sample_1951  0.928\n",
       "147   sample_386  0.967\n",
       "148   sample_362  0.934\n",
       "149   sample_522  0.932\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def modeling_cross_validation(params, X, y, nr_folds=5):\n",
    "    \n",
    "#     oof_preds = np.zeros(X.shape[0])\n",
    "#     # Split data with kfold\n",
    "#     folds = KFold(n_splits=nr_folds, shuffle=False, random_state=4096)\n",
    "    \n",
    "#     for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "#         print(\"fold n°{}\".format(fold_+1))\n",
    "#         trn_data = lgb.Dataset(X[trn_idx], y[trn_idx])\n",
    "#         val_data = lgb.Dataset(X[val_idx], y[val_idx])\n",
    "\n",
    "#         num_round = 20000\n",
    "#         clf = lgb.train(params, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 100)\n",
    "#         oof_preds[val_idx] = clf.predict(X[val_idx], num_iteration=clf.best_iteration)\n",
    "\n",
    "#     score = mean_squared_error(oof_preds, target)\n",
    "    \n",
    "#     return  score/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def featureSelect(init_cols):\n",
    "#     params = {'num_leaves': 120,\n",
    "#              'min_data_in_leaf': 30, \n",
    "#              'objective':'regression',\n",
    "#              'max_depth': -1,\n",
    "#              'learning_rate': 0.05,\n",
    "#              \"min_child_samples\": 30,\n",
    "#              \"boosting\": \"gbdt\",\n",
    "#              \"feature_fraction\": 0.9,\n",
    "#              \"bagging_freq\": 1,\n",
    "#              \"bagging_fraction\": 0.9 ,\n",
    "#              \"bagging_seed\": 11,\n",
    "#              \"metric\": 'mse',\n",
    "#              \"lambda_l1\": 0.02,\n",
    "#              \"verbosity\": -1}\n",
    "#     best_cols = init_cols.copy()\n",
    "#     best_score = modeling_cross_validation(params, train[init_cols].values, target.values, nr_folds=5)\n",
    "#     print(\"初始CV score: {:<8.8f}\".format(best_score))\n",
    "#     for f in init_cols:\n",
    "\n",
    "#         best_cols.remove(f)\n",
    "#         score = modeling_cross_validation(params, train[best_cols].values, target.values, nr_folds=5)\n",
    "#         diff = best_score - score\n",
    "#         print('-'*10)\n",
    "#         if diff > 0.0000002:\n",
    "#             print(\"当前移除特征: {}, CV score: {:<8.8f}, 最佳cv score: {:<8.8f}, 有效果,删除！！\".format(f,score,best_score))\n",
    "#             best_score = score\n",
    "#         else:\n",
    "#             print(\"当前移除特征: {}, CV score: {:<8.8f}, 最佳cv score: {:<8.8f}, 没效果,保留！！\".format(f,score,best_score))\n",
    "#             best_cols.append(f)\n",
    "#     print('-'*10)\n",
    "#     print(\"优化后CV score: {:<8.8f}\".format(best_score))\n",
    "    \n",
    "#     return best_cols\n",
    "    \n",
    "# best_features = featureSelect(train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
