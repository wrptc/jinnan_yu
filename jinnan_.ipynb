{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "#from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('jinnan_round1_train_20181227.csv', encoding = 'gb18030')\n",
    "test  = pd.read_csv('jinnan_round1_testA_20181227.csv', encoding = 'gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>样本id</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "      <th>A17</th>\n",
       "      <th>A18</th>\n",
       "      <th>A19</th>\n",
       "      <th>A20</th>\n",
       "      <th>A21</th>\n",
       "      <th>A22</th>\n",
       "      <th>A23</th>\n",
       "      <th>A24</th>\n",
       "      <th>A25</th>\n",
       "      <th>A26</th>\n",
       "      <th>A27</th>\n",
       "      <th>A28</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B9</th>\n",
       "      <th>B10</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>B13</th>\n",
       "      <th>B14</th>\n",
       "      <th>收率</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_1528</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:30:00</td>\n",
       "      <td>100</td>\n",
       "      <td>16:30:00</td>\n",
       "      <td>102</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>21:00-21:30</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>75</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>70</td>\n",
       "      <td>6:30-7:00</td>\n",
       "      <td>350.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7:00-8:00</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>65</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11:30-13:00</td>\n",
       "      <td>14:00-15:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>400</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1698</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>101</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>19:00-20:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>73</td>\n",
       "      <td>21:00-22:00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22:00-23:00</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>6:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6:00-7:30</td>\n",
       "      <td>7:30-9:00</td>\n",
       "      <td>9:00-10:00</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>400</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_639</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>102</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>19:00-19:30</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>79</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>73</td>\n",
       "      <td>21:00-22:00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22:00-23:00</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>1:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1:00-2:30</td>\n",
       "      <td>2:30-4:00</td>\n",
       "      <td>4:00-5:00</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>400</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_483</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>1:30:00</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>102</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5:00:00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>6:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>6:30-7:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7:30:00</td>\n",
       "      <td>70</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>78</td>\n",
       "      <td>13:30-14:30</td>\n",
       "      <td>290.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>14:30-15:30</td>\n",
       "      <td>15:30:00</td>\n",
       "      <td>65</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>19:00-20:30</td>\n",
       "      <td>21:30-23:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>400</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_617</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>101</td>\n",
       "      <td>1:00:00</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2:00:00</td>\n",
       "      <td>104.0</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>200</td>\n",
       "      <td>3:00-4:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>5:00:00</td>\n",
       "      <td>73</td>\n",
       "      <td>5:00-6:00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6:00-7:00</td>\n",
       "      <td>7:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>9:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9:00-10:30</td>\n",
       "      <td>10:30-12:00</td>\n",
       "      <td>12:00-13:00</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>420</td>\n",
       "      <td>0.983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          样本id   A1  A2     A3   A4        A5    A6   A7  A8        A9  A10  \\\n",
       "0  sample_1528  300 NaN  405.0  700  13:30:00  38.0  NaN NaN  15:30:00  100   \n",
       "1  sample_1698  300 NaN  405.0  700  14:00:00  29.0  NaN NaN  16:00:00  101   \n",
       "2   sample_639  300 NaN  405.0  700  14:00:00  29.0  NaN NaN  16:00:00  102   \n",
       "3   sample_483  300 NaN  405.0  700   1:30:00  38.0  NaN NaN   3:00:00  100   \n",
       "4   sample_617  300 NaN  405.0  700  22:00:00  29.0  NaN NaN   0:00:00  101   \n",
       "\n",
       "        A11  A12  A13       A14    A15       A16    A17  A18  A19  \\\n",
       "0  16:30:00  102  0.2  17:30:00  103.0  18:30:00  104.0  0.2  300   \n",
       "1  17:00:00  103  0.2  18:00:00  104.0  19:00:00  105.0  0.2  200   \n",
       "2  17:00:00  103  0.2  18:00:00  104.0  19:00:00  105.0  0.2  200   \n",
       "3   4:00:00  102  0.2   5:00:00  103.0   6:00:00  104.0  0.2  200   \n",
       "4   1:00:00  103  0.2   2:00:00  104.0   3:00:00  105.0  0.2  200   \n",
       "\n",
       "           A20   A21   A22  A23       A24 A25       A26  A27          A28  \\\n",
       "0  21:00-21:30  50.0   9.0  5.0  22:00:00  75  22:30:00   70    6:30-7:00   \n",
       "1  19:00-20:00  50.0   9.0  5.0  20:00:00  80  21:00:00   73  21:00-22:00   \n",
       "2  19:00-19:30  50.0   9.0  5.0  20:00:00  79  21:00:00   73  21:00-22:00   \n",
       "3    6:30-7:00  50.0  10.0  5.0   7:30:00  70   8:00:00   78  13:30-14:30   \n",
       "4    3:00-4:00  50.0   9.0  5.0   4:00:00  80   5:00:00   73    5:00-6:00   \n",
       "\n",
       "      B1   B2   B3           B4        B5  B6        B7    B8           B9  \\\n",
       "0  350.0  3.5  3.5    7:00-8:00   8:00:00  65  11:30:00  45.0  11:30-13:00   \n",
       "1  320.0  3.5  3.5  22:00-23:00  23:00:00  80   6:00:00  45.0    6:00-7:30   \n",
       "2  320.0  3.5  3.5  22:00-23:00  23:00:00  80   1:00:00  45.0    1:00-2:30   \n",
       "3  290.0  3.5  3.5  14:30-15:30  15:30:00  65  18:00:00  45.0  19:00-20:30   \n",
       "4  320.0  3.5  3.5    6:00-7:00   7:00:00  80   9:00:00  45.0   9:00-10:30   \n",
       "\n",
       "           B10          B11     B12   B13  B14     收率  \n",
       "0  14:00-15:30          NaN   800.0  0.15  400  0.879  \n",
       "1    7:30-9:00   9:00-10:00  1200.0  0.15  400  0.902  \n",
       "2    2:30-4:00    4:00-5:00  1200.0  0.15  400  0.936  \n",
       "3  21:30-23:00          NaN   800.0  0.15  400  0.902  \n",
       "4  10:30-12:00  12:00-13:00  1200.0  0.15  420  0.983  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cols = list(train.columns)\n",
    "# for col in train.columns:\n",
    "#     rate = train[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "#     if rate > 0.9:\n",
    "#         good_cols.remove(col)\n",
    "#         print(col,rate)\n",
    "\n",
    "train = train[train['收率']>0.885]\n",
    "        \n",
    "train = train[good_cols]\n",
    "good_cols.remove('收率')\n",
    "test  = test[good_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['收率']\n",
    "del train['收率']\n",
    "data = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "data = data.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeTranSecond(t):\n",
    "    try:\n",
    "        t,m,s=t.split(\":\")\n",
    "    except:\n",
    "        if t=='1900/1/9 7:00':\n",
    "            return (23*3600 + 20*60)/3600\n",
    "        elif t=='1900/1/1 2:30':\n",
    "            return (21*3600 + 30*60)/3600\n",
    "        elif t == '1900/1/21 0:00':\n",
    "            return 21\n",
    "        elif t == '1900/1/29 0:00':\n",
    "            return 14\n",
    "        elif t == '1900/1/12 0:00':\n",
    "            return 12\n",
    "        elif t == '1900/3/13 0:00':\n",
    "            return 13\n",
    "        elif t == '1900/1/22 0:00':\n",
    "            return 22\n",
    "        elif t == '700':\n",
    "            return 7\n",
    "        elif t==-1:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    try:\n",
    "        tm = (int(t)*3600+int(m)*60+int(s))/3600\n",
    "    except:\n",
    "        return (30*60)/3600\n",
    "    \n",
    "    return tm\n",
    "for f in ['A5','A7','A9','A11','A14','A16','A24','A26','B5','B7']:\n",
    "    data[f] = data[f].apply(timeTranSecond)\n",
    "\n",
    "def getDuration(se):\n",
    "    try:\n",
    "        sh,sm,eh,em=re.findall(r\"\\d+\\.?\\d*\",se)\n",
    "    except:\n",
    "        if se == -1:\n",
    "            return -1 \n",
    "        \n",
    "    try:\n",
    "        if int(sh)>int(eh):\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600 + 24\n",
    "        else:\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600\n",
    "    except:\n",
    "        if se=='19:-20:05':\n",
    "            return 1\n",
    "        elif se=='15:00-1600':\n",
    "            return 1\n",
    "    \n",
    "    return tm\n",
    "\n",
    "def get_start(se):\n",
    "    try:\n",
    "        sh, sm, eh, em = re.findall(r'\\d+\\.?d*', se)\n",
    "    except:\n",
    "        if se == -1:\n",
    "            return -1\n",
    "    try:\n",
    "        tm = (int(eh) * 3600 + int(em) * 60)/3600\n",
    "    except:\n",
    "        if se == '19:-20:05':\n",
    "            return 19\n",
    "        elif se == '15:00-1600':\n",
    "            return 15\n",
    "    return tm\n",
    "for f in ['A20','A28','B4','B9','B10','B11']:\n",
    "    data[f+'_diff'] = data.apply(lambda df: getDuration(df[f]), axis=1)\n",
    "for f in ['A20','A28','B4','B9','B10','B11']:\n",
    "    data[f] = data.apply(lambda df: get_start(df[f]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_point = ['A5','A7','A9','A11','A14','A16','A20', 'A24','A26','A28','B4','B5','B7','B9','B10','B11']\n",
    "time_period = ['A20','A28','B4','B9','B10','B11']\n",
    "\n",
    "for i, col in enumerate(time_point):\n",
    "    if i == len(time_point)-2:\n",
    "        break\n",
    "    nex_col = time_point[i+1]\n",
    "    col_name = nex_col + '-' + col\n",
    "    if col not in time_period:\n",
    "        data[col_name] = data[nex_col] - data[col]        \n",
    "    else:\n",
    "        data[col_name] = data[nex_col] - data[col] - data[col + '_diff']\n",
    "    data[col_name] = data[col_name].apply(lambda x: divmod(x, 24)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['样本id'] = data['样本id'].apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "categorical_columns = [f for f in data.columns if f not in ['样本id']]\n",
    "numerical_columns = [f for f in data.columns if f not in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>样本id</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "      <th>A17</th>\n",
       "      <th>A19</th>\n",
       "      <th>A20</th>\n",
       "      <th>A21</th>\n",
       "      <th>A22</th>\n",
       "      <th>A24</th>\n",
       "      <th>A25</th>\n",
       "      <th>A26</th>\n",
       "      <th>A27</th>\n",
       "      <th>A28</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B9</th>\n",
       "      <th>B10</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>B14</th>\n",
       "      <th>A20_diff</th>\n",
       "      <th>A28_diff</th>\n",
       "      <th>B4_diff</th>\n",
       "      <th>B9_diff</th>\n",
       "      <th>B10_diff</th>\n",
       "      <th>B11_diff</th>\n",
       "      <th>A7-A5</th>\n",
       "      <th>A9-A7</th>\n",
       "      <th>A11-A9</th>\n",
       "      <th>A14-A11</th>\n",
       "      <th>A16-A14</th>\n",
       "      <th>A20-A16</th>\n",
       "      <th>A24-A20</th>\n",
       "      <th>A26-A24</th>\n",
       "      <th>A28-A26</th>\n",
       "      <th>B4-A28</th>\n",
       "      <th>B5-B4</th>\n",
       "      <th>B7-B5</th>\n",
       "      <th>B9-B7</th>\n",
       "      <th>B10-B9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1698</td>\n",
       "      <td>300</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>101</td>\n",
       "      <td>17.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>200</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>80</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>639</td>\n",
       "      <td>300</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>102</td>\n",
       "      <td>17.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>200</td>\n",
       "      <td>19.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>79</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>400</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>483</td>\n",
       "      <td>300</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>1.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>4.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>200</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>70</td>\n",
       "      <td>8.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>290.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>65</td>\n",
       "      <td>18.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>400</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>617</td>\n",
       "      <td>300</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80</td>\n",
       "      <td>5.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>80</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>420</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>373</td>\n",
       "      <td>300</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>100</td>\n",
       "      <td>4.5</td>\n",
       "      <td>103.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>104.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>300</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>12.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>420</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   样本id   A1   A2     A3   A4    A5    A6   A7    A8    A9  A10   A11    A12  \\\n",
       "0  1698  300 -1.0  405.0  700  14.0  29.0 -1.0  -1.0  16.0  101  17.0  103.0   \n",
       "1   639  300 -1.0  405.0  700  14.0  29.0 -1.0  -1.0  16.0  102  17.0  103.0   \n",
       "2   483  300 -1.0  405.0  700   1.5  38.0 -1.0  -1.0   3.0  100   4.0  102.0   \n",
       "3   617  300 -1.0  405.0  700  22.0  29.0 -1.0  -1.0   0.0  101   1.0  103.0   \n",
       "4   373  300 -1.0  405.0  700   2.0  39.0  2.5  80.0   3.5  100   4.5  103.0   \n",
       "\n",
       "    A14    A15   A16    A17  A19   A20   A21   A22   A24 A25   A26   A27  \\\n",
       "0  18.0  104.0  19.0  105.0  200  20.0  50.0   9.0  20.0  80  21.0  73.0   \n",
       "1  18.0  104.0  19.0  105.0  200  19.5  50.0   9.0  20.0  79  21.0  73.0   \n",
       "2   5.0  103.0   6.0  104.0  200   7.0  50.0  10.0   7.5  70   8.0  78.0   \n",
       "3   2.0  104.0   3.0  105.0  200   4.0  50.0   9.0   4.0  80   5.0  73.0   \n",
       "4   5.5  104.0   6.5  102.0  300  12.0  50.0   9.0  12.0  70  12.5  75.0   \n",
       "\n",
       "    A28     B1   B2    B4    B5  B6    B7    B8    B9   B10   B11     B12  \\\n",
       "0  22.0  320.0  3.5  23.0  23.0  80   6.0  45.0   7.5   9.0  10.0  1200.0   \n",
       "1  22.0  320.0  3.5  23.0  23.0  80   1.0  45.0   2.5   4.0   5.0  1200.0   \n",
       "2  14.5  290.0  3.5  15.5  15.5  65  18.0  45.0  20.5  23.0  -1.0   800.0   \n",
       "3   6.0  320.0  3.5   7.0   7.0  80   9.0  45.0  10.5  12.0  13.0  1200.0   \n",
       "4  18.0   -1.0  3.5  20.0  20.0  65   3.0  45.0   4.5   7.0  -1.0   800.0   \n",
       "\n",
       "   B14  A20_diff  A28_diff  B4_diff  B9_diff  B10_diff  B11_diff  A7-A5  \\\n",
       "0  400       1.0       1.0      1.0      1.5       1.5       1.0    9.0   \n",
       "1  400       0.5       1.0      1.0      1.5       1.5       1.0    9.0   \n",
       "2  400       0.5       1.0      1.0      1.5       1.5      -1.0   21.5   \n",
       "3  420       1.0       1.0      1.0      1.5       1.5       1.0    1.0   \n",
       "4  420       0.5       0.5      2.0      1.5       1.5      -1.0    0.5   \n",
       "\n",
       "   A9-A7  A11-A9  A14-A11  A16-A14  A20-A16  A24-A20  A26-A24  A28-A26  \\\n",
       "0   17.0     1.0      1.0      1.0      1.0     23.0      1.0      1.0   \n",
       "1   17.0     1.0      1.0      1.0      0.5      0.0      1.0      1.0   \n",
       "2    4.0     1.0      1.0      1.0      1.0      0.0      0.5      6.5   \n",
       "3    1.0     1.0      1.0      1.0      1.0     23.0      1.0      1.0   \n",
       "4    1.0     1.0      1.0      1.0      5.5     23.5      0.5      5.5   \n",
       "\n",
       "   B4-A28  B5-B4  B7-B5  B9-B7  B10-B9  \n",
       "0     0.0   23.0    7.0    1.5     0.0  \n",
       "1     0.0   23.0    2.0    1.5     0.0  \n",
       "2     0.0   23.0    2.5    2.5     1.0  \n",
       "3     0.0   23.0    2.0    1.5     0.0  \n",
       "4     1.5   22.0    7.0    1.5     1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['A1', 'A2', 'A3', 'A4', 'A6', 'A8', 'A10', 'A12', 'A13', 'A15', 'A17', 'A18', 'A19', 'A21', 'A22', 'A23', 'A25', 'A27', 'B1', 'B2', 'B3', 'B6', 'B8', 'B12', 'B13', 'B14']\n",
    "\n",
    "for col in num_cols:\n",
    "    if col in data.columns:\n",
    "        numerical_columns.append(col)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['b14/a1_a3_a4_a19_b1_b12'] = data['B14']/(data['A1']+data['A3']+data['A4']+data['A19']+data['B1']+data['B12'])\n",
    "\n",
    "numerical_columns.append('b14/a1_a3_a4_a19_b1_b12')\n",
    "\n",
    "# del data['A1']\n",
    "# del data['A3']\n",
    "# del data['A4']\n",
    "# categorical_columns.remove('A1')\n",
    "# categorical_columns.remove('A3')\n",
    "# categorical_columns.remove('A4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1308, 59)\n",
      "(150, 59)\n"
     ]
    }
   ],
   "source": [
    "for f in categorical_columns:\n",
    "    data[f] = data[f].map(dict(zip(data[f].unique(), range(0, data[f].nunique()))))\n",
    "train = data[:train.shape[0]]\n",
    "test  = data[train.shape[0]:]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1308, 229)\n",
      "(150, 229)\n"
     ]
    }
   ],
   "source": [
    "train['target'] = target\n",
    "train['intTarget'] = pd.cut(train['target'], 5, labels=False)\n",
    "train = pd.get_dummies(train, columns=['intTarget'])\n",
    "li = ['intTarget_0.0','intTarget_1.0','intTarget_2.0','intTarget_3.0','intTarget_4.0']\n",
    "mean_columns = []\n",
    "for f1 in categorical_columns:\n",
    "    cate_rate = train[f1].value_counts(normalize=True, dropna=False).values[0]\n",
    "    if cate_rate < 0.90:\n",
    "        for f2 in li:\n",
    "            col_name = 'B14_to_'+f1+\"_\"+f2+'_mean'\n",
    "            mean_columns.append(col_name)\n",
    "            order_label = train.groupby([f1])[f2].mean()\n",
    "            train[col_name] = train['B14'].map(order_label)\n",
    "            miss_rate = train[col_name].isnull().sum() * 100 / train[col_name].shape[0]\n",
    "            if miss_rate > 0:\n",
    "                train = train.drop([col_name], axis=1)\n",
    "                mean_columns.remove(col_name)\n",
    "            else:\n",
    "                test[col_name] = test['B14'].map(order_label)\n",
    "                \n",
    "                \n",
    "                \n",
    "#             col_name = f1+\"_\"+f2+'_mean'\n",
    "#             mean_columns.append(col_name)\n",
    "#             order_label = train.groupby([f1])[f2].mean()\n",
    "#             train[col_name] = train[f1].map(order_label)\n",
    "#             miss_rate = train[col_name].isnull().sum() * 100 / train[col_name].shape[0]\n",
    "#             if miss_rate > 0:\n",
    "#                 train = train.drop([col_name], axis=1)\n",
    "#                 mean_columns.remove(col_name)\n",
    "#             else:\n",
    "#                 test[col_name] = test[f1].map(order_label)\n",
    "            \n",
    "                        \n",
    "train.drop(li+['target'], axis=1, inplace=True)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ = pd.DataFrame(train, columns=best_features)\n",
    "# test_ = pd.DataFrame(test, columns=best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train_.values\n",
    "# X_test = test_.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[mean_columns+numerical_columns].values\n",
    "X_test = test[mean_columns+numerical_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1308, 2306)\n",
      "(150, 2306)\n"
     ]
    }
   ],
   "source": [
    "# one hot\n",
    "enc = OneHotEncoder()\n",
    "for f in categorical_columns:\n",
    "    enc.fit(data[f].values.reshape(-1, 1))\n",
    "    X_train = sparse.hstack((X_train, enc.transform(train[f].values.reshape(-1, 1))), 'csr')\n",
    "    X_test = sparse.hstack((X_test, enc.transform(test[f].values.reshape(-1, 1))), 'csr')\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_params = {'learning_rate': 0.1,\n",
    "#               'depth': 12,\n",
    "#               'l2_leaf_reg': 10,\n",
    "#               'bootstrap_type': 'Bernoulli',\n",
    "#               'od_type': 'Iter',\n",
    "#               'od_wait': 50,\n",
    "#               'random_seed': 11,\n",
    "#               'allow_writing_files': False}\n",
    "# folds = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "# oof_cat = np.zeros(len(train))\n",
    "# predictions_cat = np.zeros(len(test))\n",
    "# for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "#     print(f\"fold {fold_+1}\")\n",
    "#     (trn_data_X, trn_data_y, val_data_X, val_data_y) = (\n",
    "#         X_train.toarray()[trn_idx],\n",
    "#         y_train[trn_idx],\n",
    "#         X_train.toarray()[val_idx],\n",
    "#         y_train[val_idx])\n",
    "#     clf = CatBoostRegressor(iterations=20000, eval_metric='RMSE', use_best_model=True, **cat_params)\n",
    "#     clf.fit(trn_data_X, trn_data_y,\n",
    "#             eval_set=(val_data_X, val_data_y),\n",
    "#             logging_level='Verbose')\n",
    "#     oof_cat[val_idx] = clf.predict(val_data_X)\n",
    "    \n",
    "#     predictions_cat += clf.predict(X_test.toarray()) / folds.n_splits\n",
    "    \n",
    "# print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_cat, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000197451\tvalid_1's l2: 0.000232253\n",
      "[400]\ttraining's l2: 0.000103471\tvalid_1's l2: 0.000145352\n",
      "[600]\ttraining's l2: 7.69892e-05\tvalid_1's l2: 0.00012644\n",
      "[800]\ttraining's l2: 6.20023e-05\tvalid_1's l2: 0.000118488\n",
      "[1000]\ttraining's l2: 5.26371e-05\tvalid_1's l2: 0.000115458\n",
      "[1200]\ttraining's l2: 4.60089e-05\tvalid_1's l2: 0.000114457\n",
      "Early stopping, best iteration is:\n",
      "[1247]\ttraining's l2: 4.47083e-05\tvalid_1's l2: 0.00011429\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.00019952\tvalid_1's l2: 0.000219427\n",
      "[400]\ttraining's l2: 0.000106869\tvalid_1's l2: 0.000138019\n",
      "[600]\ttraining's l2: 7.90592e-05\tvalid_1's l2: 0.000121493\n",
      "[800]\ttraining's l2: 6.42427e-05\tvalid_1's l2: 0.000114958\n",
      "[1000]\ttraining's l2: 5.49385e-05\tvalid_1's l2: 0.00011388\n",
      "[1200]\ttraining's l2: 4.83849e-05\tvalid_1's l2: 0.000113703\n",
      "Early stopping, best iteration is:\n",
      "[1160]\ttraining's l2: 4.9569e-05\tvalid_1's l2: 0.000113661\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000200883\tvalid_1's l2: 0.000224748\n",
      "[400]\ttraining's l2: 0.000108969\tvalid_1's l2: 0.000121499\n",
      "[600]\ttraining's l2: 8.09027e-05\tvalid_1's l2: 9.80914e-05\n",
      "[800]\ttraining's l2: 6.4955e-05\tvalid_1's l2: 9.09487e-05\n",
      "[1000]\ttraining's l2: 5.52771e-05\tvalid_1's l2: 8.98666e-05\n",
      "Early stopping, best iteration is:\n",
      "[946]\ttraining's l2: 5.7532e-05\tvalid_1's l2: 8.96769e-05\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000199354\tvalid_1's l2: 0.000250458\n",
      "[400]\ttraining's l2: 0.000103112\tvalid_1's l2: 0.000164591\n",
      "[600]\ttraining's l2: 7.6301e-05\tvalid_1's l2: 0.000144381\n",
      "[800]\ttraining's l2: 6.21713e-05\tvalid_1's l2: 0.00013316\n",
      "[1000]\ttraining's l2: 5.28896e-05\tvalid_1's l2: 0.000128403\n",
      "[1200]\ttraining's l2: 4.6488e-05\tvalid_1's l2: 0.000126653\n",
      "[1400]\ttraining's l2: 4.16599e-05\tvalid_1's l2: 0.000125855\n",
      "[1600]\ttraining's l2: 3.78619e-05\tvalid_1's l2: 0.00012551\n",
      "[1800]\ttraining's l2: 3.45992e-05\tvalid_1's l2: 0.000125348\n",
      "Early stopping, best iteration is:\n",
      "[1823]\ttraining's l2: 3.42867e-05\tvalid_1's l2: 0.000125299\n",
      "fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000196023\tvalid_1's l2: 0.00019761\n",
      "[400]\ttraining's l2: 9.77941e-05\tvalid_1's l2: 0.000143845\n",
      "[600]\ttraining's l2: 7.10075e-05\tvalid_1's l2: 0.000134875\n",
      "[800]\ttraining's l2: 5.72535e-05\tvalid_1's l2: 0.000131727\n",
      "[1000]\ttraining's l2: 4.91031e-05\tvalid_1's l2: 0.000130135\n",
      "[1200]\ttraining's l2: 4.34563e-05\tvalid_1's l2: 0.000129512\n",
      "[1400]\ttraining's l2: 3.91049e-05\tvalid_1's l2: 0.00012909\n",
      "Early stopping, best iteration is:\n",
      "[1405]\ttraining's l2: 3.89964e-05\tvalid_1's l2: 0.000129072\n",
      "CV score: 0.00011438\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 120,\n",
    "         'min_data_in_leaf': 12, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8,\n",
    "         \"bagging_seed\": 6,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.01,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "feature_importance = np.zeros(X_train.shape[1])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(f\"fold {fold_+1}\")\n",
    "    trn_data = lgb.Dataset(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train[val_idx], num_iteration=clf.best_iteration)    \n",
    "    predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    feature_importance += clf.feature_importance() / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_features = []\n",
    "for i, imp in enumerate(feature_importance):\n",
    "    if imp > 30:\n",
    "        good_features.append(i)\n",
    "X_train = X_train[:, good_features]\n",
    "X_test = X_test[:, good_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000197505\tvalid_1's l2: 0.000227678\n",
      "[400]\ttraining's l2: 0.00010416\tvalid_1's l2: 0.000139407\n",
      "[600]\ttraining's l2: 7.7606e-05\tvalid_1's l2: 0.000119322\n",
      "[800]\ttraining's l2: 6.27951e-05\tvalid_1's l2: 0.000110689\n",
      "[1000]\ttraining's l2: 5.34238e-05\tvalid_1's l2: 0.000107099\n",
      "[1200]\ttraining's l2: 4.69963e-05\tvalid_1's l2: 0.00010629\n",
      "Early stopping, best iteration is:\n",
      "[1292]\ttraining's l2: 4.45827e-05\tvalid_1's l2: 0.000106125\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000200285\tvalid_1's l2: 0.000219496\n",
      "[400]\ttraining's l2: 0.000106494\tvalid_1's l2: 0.000136344\n",
      "[600]\ttraining's l2: 7.93704e-05\tvalid_1's l2: 0.000120166\n",
      "[800]\ttraining's l2: 6.45523e-05\tvalid_1's l2: 0.000113556\n",
      "[1000]\ttraining's l2: 5.50935e-05\tvalid_1's l2: 0.000111909\n",
      "[1200]\ttraining's l2: 4.86253e-05\tvalid_1's l2: 0.00011136\n",
      "[1400]\ttraining's l2: 4.37045e-05\tvalid_1's l2: 0.000111311\n",
      "Early stopping, best iteration is:\n",
      "[1365]\ttraining's l2: 4.44676e-05\tvalid_1's l2: 0.000111186\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000202219\tvalid_1's l2: 0.000226159\n",
      "[400]\ttraining's l2: 0.000109378\tvalid_1's l2: 0.000120752\n",
      "[600]\ttraining's l2: 8.1268e-05\tvalid_1's l2: 9.72347e-05\n",
      "[800]\ttraining's l2: 6.53431e-05\tvalid_1's l2: 8.98085e-05\n",
      "[1000]\ttraining's l2: 5.57124e-05\tvalid_1's l2: 8.79707e-05\n",
      "Early stopping, best iteration is:\n",
      "[1000]\ttraining's l2: 5.57124e-05\tvalid_1's l2: 8.79707e-05\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000199589\tvalid_1's l2: 0.000251363\n",
      "[400]\ttraining's l2: 0.000103661\tvalid_1's l2: 0.000165195\n",
      "[600]\ttraining's l2: 7.68605e-05\tvalid_1's l2: 0.000144577\n",
      "[800]\ttraining's l2: 6.24586e-05\tvalid_1's l2: 0.000132725\n",
      "[1000]\ttraining's l2: 5.32264e-05\tvalid_1's l2: 0.000127997\n",
      "[1200]\ttraining's l2: 4.68777e-05\tvalid_1's l2: 0.000125979\n",
      "[1400]\ttraining's l2: 4.21786e-05\tvalid_1's l2: 0.000124971\n",
      "[1600]\ttraining's l2: 3.83625e-05\tvalid_1's l2: 0.000124375\n",
      "Early stopping, best iteration is:\n",
      "[1682]\ttraining's l2: 3.69889e-05\tvalid_1's l2: 0.000124179\n",
      "fold 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000196042\tvalid_1's l2: 0.000197393\n",
      "[400]\ttraining's l2: 9.8433e-05\tvalid_1's l2: 0.000144076\n",
      "[600]\ttraining's l2: 7.17545e-05\tvalid_1's l2: 0.00013525\n",
      "[800]\ttraining's l2: 5.7714e-05\tvalid_1's l2: 0.000131975\n",
      "[1000]\ttraining's l2: 4.94828e-05\tvalid_1's l2: 0.00013041\n",
      "[1200]\ttraining's l2: 4.3806e-05\tvalid_1's l2: 0.000129753\n",
      "[1400]\ttraining's l2: 3.93648e-05\tvalid_1's l2: 0.000129523\n",
      "Early stopping, best iteration is:\n",
      "[1405]\ttraining's l2: 3.92577e-05\tvalid_1's l2: 0.000129487\n",
      "CV score: 0.00011177\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 120,\n",
    "         'min_data_in_leaf': 12, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8,\n",
    "         \"bagging_seed\": 6,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.01,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(f\"fold {fold_+1}\")\n",
    "    trn_data = lgb.Dataset(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:0.426064\tvalid_data-rmse:0.423398\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.258872\tvalid_data-rmse:0.256757\n",
      "[200]\ttrain-rmse:0.15772\tvalid_data-rmse:0.156128\n",
      "[300]\ttrain-rmse:0.096523\tvalid_data-rmse:0.095324\n",
      "[400]\ttrain-rmse:0.059627\tvalid_data-rmse:0.058699\n",
      "[500]\ttrain-rmse:0.037382\tvalid_data-rmse:0.03692\n",
      "[600]\ttrain-rmse:0.024056\tvalid_data-rmse:0.024286\n",
      "[700]\ttrain-rmse:0.016104\tvalid_data-rmse:0.017294\n",
      "[800]\ttrain-rmse:0.011269\tvalid_data-rmse:0.013614\n",
      "[900]\ttrain-rmse:0.008333\tvalid_data-rmse:0.011836\n",
      "[1000]\ttrain-rmse:0.006515\tvalid_data-rmse:0.011016\n",
      "[1100]\ttrain-rmse:0.005313\tvalid_data-rmse:0.010669\n",
      "[1200]\ttrain-rmse:0.004506\tvalid_data-rmse:0.010509\n",
      "[1300]\ttrain-rmse:0.003898\tvalid_data-rmse:0.010442\n",
      "[1400]\ttrain-rmse:0.003438\tvalid_data-rmse:0.010425\n",
      "[1500]\ttrain-rmse:0.003069\tvalid_data-rmse:0.01043\n",
      "[1600]\ttrain-rmse:0.002757\tvalid_data-rmse:0.010436\n",
      "Stopping. Best iteration:\n",
      "[1441]\ttrain-rmse:0.003275\tvalid_data-rmse:0.010423\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:0.42509\tvalid_data-rmse:0.427311\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.258288\tvalid_data-rmse:0.259968\n",
      "[200]\ttrain-rmse:0.15736\tvalid_data-rmse:0.158622\n",
      "[300]\ttrain-rmse:0.096323\tvalid_data-rmse:0.097094\n",
      "[400]\ttrain-rmse:0.059504\tvalid_data-rmse:0.059902\n",
      "[500]\ttrain-rmse:0.03734\tvalid_data-rmse:0.037685\n",
      "[600]\ttrain-rmse:0.024086\tvalid_data-rmse:0.024751\n",
      "[700]\ttrain-rmse:0.016151\tvalid_data-rmse:0.0175\n",
      "[800]\ttrain-rmse:0.01133\tvalid_data-rmse:0.013658\n",
      "[900]\ttrain-rmse:0.008403\tvalid_data-rmse:0.011829\n",
      "[1000]\ttrain-rmse:0.006584\tvalid_data-rmse:0.011\n",
      "[1100]\ttrain-rmse:0.005392\tvalid_data-rmse:0.010683\n",
      "[1200]\ttrain-rmse:0.004582\tvalid_data-rmse:0.010572\n",
      "[1300]\ttrain-rmse:0.003993\tvalid_data-rmse:0.010547\n",
      "[1400]\ttrain-rmse:0.003517\tvalid_data-rmse:0.010546\n",
      "[1500]\ttrain-rmse:0.003141\tvalid_data-rmse:0.010555\n",
      "Stopping. Best iteration:\n",
      "[1309]\ttrain-rmse:0.003947\tvalid_data-rmse:0.010541\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:0.425294\tvalid_data-rmse:0.426508\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.258393\tvalid_data-rmse:0.259312\n",
      "[200]\ttrain-rmse:0.157436\tvalid_data-rmse:0.158189\n",
      "[300]\ttrain-rmse:0.096391\tvalid_data-rmse:0.096907\n",
      "[400]\ttrain-rmse:0.059623\tvalid_data-rmse:0.060012\n",
      "[500]\ttrain-rmse:0.037471\tvalid_data-rmse:0.037797\n",
      "[600]\ttrain-rmse:0.024164\tvalid_data-rmse:0.024644\n",
      "[700]\ttrain-rmse:0.016186\tvalid_data-rmse:0.017125\n",
      "[800]\ttrain-rmse:0.011359\tvalid_data-rmse:0.013046\n",
      "[900]\ttrain-rmse:0.008426\tvalid_data-rmse:0.011036\n",
      "[1000]\ttrain-rmse:0.006612\tvalid_data-rmse:0.010139\n",
      "[1100]\ttrain-rmse:0.005421\tvalid_data-rmse:0.009799\n",
      "[1200]\ttrain-rmse:0.004612\tvalid_data-rmse:0.009695\n",
      "[1300]\ttrain-rmse:0.003999\tvalid_data-rmse:0.009702\n",
      "[1400]\ttrain-rmse:0.003535\tvalid_data-rmse:0.009749\n",
      "Stopping. Best iteration:\n",
      "[1241]\ttrain-rmse:0.004344\tvalid_data-rmse:0.009686\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:0.425131\tvalid_data-rmse:0.427168\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.25828\tvalid_data-rmse:0.260249\n",
      "[200]\ttrain-rmse:0.157362\tvalid_data-rmse:0.159138\n",
      "[300]\ttrain-rmse:0.096333\tvalid_data-rmse:0.097841\n",
      "[400]\ttrain-rmse:0.059511\tvalid_data-rmse:0.060866\n",
      "[500]\ttrain-rmse:0.037363\tvalid_data-rmse:0.038673\n",
      "[600]\ttrain-rmse:0.02405\tvalid_data-rmse:0.025516\n",
      "[700]\ttrain-rmse:0.016061\tvalid_data-rmse:0.017999\n",
      "[800]\ttrain-rmse:0.011235\tvalid_data-rmse:0.014008\n",
      "[900]\ttrain-rmse:0.008238\tvalid_data-rmse:0.012061\n",
      "[1000]\ttrain-rmse:0.006336\tvalid_data-rmse:0.011228\n",
      "[1100]\ttrain-rmse:0.005103\tvalid_data-rmse:0.01089\n",
      "[1200]\ttrain-rmse:0.004287\tvalid_data-rmse:0.010765\n",
      "[1300]\ttrain-rmse:0.003684\tvalid_data-rmse:0.010724\n",
      "[1400]\ttrain-rmse:0.003237\tvalid_data-rmse:0.010716\n",
      "[1500]\ttrain-rmse:0.002868\tvalid_data-rmse:0.010735\n",
      "Stopping. Best iteration:\n",
      "[1373]\ttrain-rmse:0.003349\tvalid_data-rmse:0.010713\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:0.426095\tvalid_data-rmse:0.423267\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.2589\tvalid_data-rmse:0.256415\n",
      "[200]\ttrain-rmse:0.157749\tvalid_data-rmse:0.155711\n",
      "[300]\ttrain-rmse:0.096563\tvalid_data-rmse:0.095212\n",
      "[400]\ttrain-rmse:0.059649\tvalid_data-rmse:0.058974\n",
      "[500]\ttrain-rmse:0.037424\tvalid_data-rmse:0.037344\n",
      "[600]\ttrain-rmse:0.02408\tvalid_data-rmse:0.024685\n",
      "[700]\ttrain-rmse:0.016084\tvalid_data-rmse:0.017723\n",
      "[800]\ttrain-rmse:0.011252\tvalid_data-rmse:0.014154\n",
      "[900]\ttrain-rmse:0.008257\tvalid_data-rmse:0.012441\n",
      "[1000]\ttrain-rmse:0.006365\tvalid_data-rmse:0.011669\n",
      "[1100]\ttrain-rmse:0.005142\tvalid_data-rmse:0.011354\n",
      "[1200]\ttrain-rmse:0.004319\tvalid_data-rmse:0.011222\n",
      "[1300]\ttrain-rmse:0.003731\tvalid_data-rmse:0.01118\n",
      "[1400]\ttrain-rmse:0.003286\tvalid_data-rmse:0.01116\n",
      "[1500]\ttrain-rmse:0.002916\tvalid_data-rmse:0.011157\n",
      "[1600]\ttrain-rmse:0.002621\tvalid_data-rmse:0.011166\n",
      "Stopping. Best iteration:\n",
      "[1497]\ttrain-rmse:0.002928\tvalid_data-rmse:0.011155\n",
      "\n",
      "CV score: 0.00011054\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'eta': 0.005, 'max_depth': 12, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 4}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "oof_xgb = np.zeros(len(train))\n",
    "predictions_xgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=100, params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(X_train[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_h2o = pd.read_csv('oof_h2o.csv', header=None).values.reshape(-1)\n",
    "# predictions_h2o = pd.read_csv('predictions_h2o.csv', header=None).values.reshape(-1)\n",
    "# print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_h2o, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack = np.vstack([oof_lgb, oof_xgb]).transpose()\n",
    "test_stack = np.vstack([predictions_lgb, predictions_xgb]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988717</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  1.000000  0.988717\n",
       "1  0.988717  1.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_stack).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "[0.33521917 0.67265584]\n",
      "fold 1\n",
      "[0.49276018 0.51792519]\n",
      "fold 2\n",
      "[0.47669842 0.52943287]\n",
      "fold 3\n",
      "[0.46093509 0.55103686]\n",
      "fold 4\n",
      "[0.46591886 0.54077703]\n",
      "fold 5\n",
      "[0.384648   0.62742759]\n",
      "fold 6\n",
      "[0.42522867 0.58280065]\n",
      "fold 7\n",
      "[0.46361774 0.55043988]\n",
      "fold 8\n",
      "[0.45679875 0.55008684]\n",
      "fold 9\n",
      "[0.50184058 0.49974726]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00010807747728576392"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=4590)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    clf_3 = BayesianRidge()\n",
    "    clf_3.fit(trn_data, trn_y)\n",
    "    print(clf_3.coef_)\n",
    "    \n",
    "    oof_stack[val_idx] = clf_3.predict(val_data)\n",
    "    predictions += clf_3.predict(test_stack) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('jinnan_round1_submit_20181227.csv', header=None)\n",
    "sub_df[1] = predictions\n",
    "sub_df[1] = sub_df[1].apply(lambda x:round(x, 3))\n",
    "sub_df.to_csv(\"submit.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42905248333333323"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sub_df[1]**2).sum()/len(sub_df.index)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_1656</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1548</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_769</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_1881</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_1807</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample_145</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sample_1212</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample_944</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample_829</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample_616</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sample_1690</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sample_114</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sample_185</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sample_1141</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sample_1460</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sample_1835</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sample_1539</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sample_598</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sample_1800</td>\n",
       "      <td>0.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sample_394</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sample_1146</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sample_149</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sample_1750</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sample_1977</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sample_1830</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sample_818</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sample_881</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sample_77</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sample_1240</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sample_309</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>sample_49</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>sample_474</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>sample_1716</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>sample_1169</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>sample_1925</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>sample_667</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>sample_176</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>sample_1908</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>sample_160</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>sample_35</td>\n",
       "      <td>0.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>sample_1403</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>sample_1806</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>sample_241</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>sample_1059</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>sample_746</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>sample_513</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>sample_1088</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>sample_1370</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>sample_523</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>sample_319</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>sample_1923</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>sample_1296</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>sample_1152</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>sample_982</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>sample_304</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>sample_502</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>sample_1951</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>sample_386</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>sample_362</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>sample_522</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1\n",
       "0    sample_1656  0.907\n",
       "1    sample_1548  0.919\n",
       "2     sample_769  0.933\n",
       "3    sample_1881  0.902\n",
       "4    sample_1807  0.927\n",
       "5     sample_145  0.927\n",
       "6    sample_1212  0.935\n",
       "7     sample_944  0.896\n",
       "8     sample_829  0.934\n",
       "9     sample_616  0.925\n",
       "10   sample_1690  0.947\n",
       "11    sample_114  0.945\n",
       "12    sample_185  0.930\n",
       "13   sample_1141  0.957\n",
       "14   sample_1460  0.897\n",
       "15   sample_1835  0.918\n",
       "16   sample_1539  0.896\n",
       "17    sample_598  0.935\n",
       "18   sample_1800  0.977\n",
       "19    sample_394  0.894\n",
       "20   sample_1146  0.907\n",
       "21    sample_149  0.976\n",
       "22   sample_1750  0.939\n",
       "23   sample_1977  0.934\n",
       "24   sample_1830  0.978\n",
       "25    sample_818  0.939\n",
       "26    sample_881  0.898\n",
       "27     sample_77  0.900\n",
       "28   sample_1240  0.975\n",
       "29    sample_309  0.895\n",
       "..           ...    ...\n",
       "120    sample_49  0.897\n",
       "121   sample_474  0.898\n",
       "122  sample_1716  0.897\n",
       "123  sample_1169  0.969\n",
       "124  sample_1925  0.934\n",
       "125   sample_667  0.928\n",
       "126   sample_176  0.928\n",
       "127  sample_1908  0.899\n",
       "128   sample_160  0.931\n",
       "129    sample_35  0.966\n",
       "130  sample_1403  0.925\n",
       "131  sample_1806  0.979\n",
       "132   sample_241  0.937\n",
       "133  sample_1059  0.941\n",
       "134   sample_746  0.946\n",
       "135   sample_513  0.935\n",
       "136  sample_1088  0.935\n",
       "137  sample_1370  0.932\n",
       "138   sample_523  0.938\n",
       "139   sample_319  0.896\n",
       "140  sample_1923  0.976\n",
       "141  sample_1296  0.944\n",
       "142  sample_1152  0.906\n",
       "143   sample_982  0.898\n",
       "144   sample_304  0.900\n",
       "145   sample_502  0.968\n",
       "146  sample_1951  0.928\n",
       "147   sample_386  0.965\n",
       "148   sample_362  0.934\n",
       "149   sample_522  0.929\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def modeling_cross_validation(params, X, y, nr_folds=5):\n",
    "    \n",
    "#     oof_preds = np.zeros(X.shape[0])\n",
    "#     # Split data with kfold\n",
    "#     folds = KFold(n_splits=nr_folds, shuffle=False, random_state=4096)\n",
    "    \n",
    "#     for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "#         print(\"fold n°{}\".format(fold_+1))\n",
    "#         trn_data = lgb.Dataset(X[trn_idx], y[trn_idx])\n",
    "#         val_data = lgb.Dataset(X[val_idx], y[val_idx])\n",
    "\n",
    "#         num_round = 20000\n",
    "#         clf = lgb.train(params, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 100)\n",
    "#         oof_preds[val_idx] = clf.predict(X[val_idx], num_iteration=clf.best_iteration)\n",
    "\n",
    "#     score = mean_squared_error(oof_preds, target)\n",
    "    \n",
    "#     return  score/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def featureSelect(init_cols):\n",
    "#     params = {'num_leaves': 120,\n",
    "#              'min_data_in_leaf': 30, \n",
    "#              'objective':'regression',\n",
    "#              'max_depth': -1,\n",
    "#              'learning_rate': 0.05,\n",
    "#              \"min_child_samples\": 30,\n",
    "#              \"boosting\": \"gbdt\",\n",
    "#              \"feature_fraction\": 0.9,\n",
    "#              \"bagging_freq\": 1,\n",
    "#              \"bagging_fraction\": 0.9 ,\n",
    "#              \"bagging_seed\": 11,\n",
    "#              \"metric\": 'mse',\n",
    "#              \"lambda_l1\": 0.02,\n",
    "#              \"verbosity\": -1}\n",
    "#     best_cols = init_cols.copy()\n",
    "#     best_score = modeling_cross_validation(params, train[init_cols].values, target.values, nr_folds=5)\n",
    "#     print(\"初始CV score: {:<8.8f}\".format(best_score))\n",
    "#     for f in init_cols:\n",
    "\n",
    "#         best_cols.remove(f)\n",
    "#         score = modeling_cross_validation(params, train[best_cols].values, target.values, nr_folds=5)\n",
    "#         diff = best_score - score\n",
    "#         print('-'*10)\n",
    "#         if diff > 0.0000002:\n",
    "#             print(\"当前移除特征: {}, CV score: {:<8.8f}, 最佳cv score: {:<8.8f}, 有效果,删除！！\".format(f,score,best_score))\n",
    "#             best_score = score\n",
    "#         else:\n",
    "#             print(\"当前移除特征: {}, CV score: {:<8.8f}, 最佳cv score: {:<8.8f}, 没效果,保留！！\".format(f,score,best_score))\n",
    "#             best_cols.append(f)\n",
    "#     print('-'*10)\n",
    "#     print(\"优化后CV score: {:<8.8f}\".format(best_score))\n",
    "    \n",
    "#     return best_cols\n",
    "    \n",
    "# best_features = featureSelect(train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
